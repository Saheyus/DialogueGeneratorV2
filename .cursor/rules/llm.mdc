---
description: LLM/OpenAI — SDK v1 AsyncOpenAI, config, tests sans réseau, GPT-5+ Responses API
globs: ["llm_client.py", "llm_client/**/*.py", "factories/**/*.py", "prompt_engine.py", "config/**/llm*.json", "llm_config.json"]
alwaysApply: false
---

- OpenAI: respecter le SDK v1 (ex: `AsyncOpenAI`) et éviter les patterns legacy.
- Ne jamais logguer de secrets. Les clés viennent des variables d'environnement/config (ex: `OPENAI_API_KEY`).
- Tests: aucune requête réseau; utiliser `DummyLLMClient` ou mocks.
- JSON: conserver compatibilité Unity (schémas Pydantic / export) et couvrir par tests.

## GPT-5 (tous modèles)

**API recommandée**: Tous les modèles GPT-5 (5.2, 5.2-pro, 5-mini, 5-nano) utilisent Responses API (`client.responses.create`) par défaut. Détermination: modèles contenant `gpt-5` → Responses API.

**Format de requête**:
- `input` au lieu de `messages` (même structure de messages)
- `max_output_tokens` au lieu de `max_tokens`/`max_completion_tokens`
- `tools`: format plat (`{"type": "function", "name": "...", "parameters": {...}}`) au lieu de `{"type": "function", "function": {...}}`
- `tool_choice`: format `{"type": "allowed_tools", "mode": "required", "tools": [...]}` au lieu de `{"type": "function", "function": {...}}`

**Reasoning (phase réflexive)**:
- Disponible pour tous les modèles GPT-5 via Responses API
- Paramètres: `reasoning.effort` (valeurs dépendent du modèle), `reasoning.summary` (None/"auto" uniquement)
- **GPT-5.2/5.2-pro** : Supportent `none`, `minimal`, `low`, `medium`, `high`, `xhigh`
- **GPT-5 mini/nano** : Supportent uniquement `minimal`, `low`, `medium`, `high` (pas `none` ni `xhigh`)
- **reasoning.summary** : Uniquement `"auto"` supporté (les résumés `"detailed"` nécessitent une organisation OpenAI vérifiée Tier 2/3, non disponible actuellement)
- Si `reasoning.effort` défini sans `summary`, `summary="auto"` activé automatiquement
- Réponse: `reasoning_trace` extrait depuis `response.reasoning` et `response.output` (item `type="reasoning"`)

**Temperature**: Supportée uniquement si `reasoning.effort` == "none" (ou non spécifié). Ignorée si `reasoning.effort` est défini. **GPT-5 mini/nano ne peuvent pas utiliser temperature via Responses API** (car pas de `none`), utiliser Chat Completions si nécessaire.

**Parsing de réponse**:
- Responses API: extraire depuis `response.output` (liste d'items, chercher `type="function_call"` ou `type="tool_call"`)
- Chat Completions: extraire depuis `response.choices[0].message.tool_calls`
- Usage tokens: `response.usage.input_tokens`/`output_tokens` (Responses) vs `prompt_tokens`/`completion_tokens` (Chat)

**Tous modèles GPT-5**: `gpt-5.2`, `gpt-5.2-pro`, `gpt-5-mini`, `gpt-5-nano` utilisent Responses API par défaut. Chat Completions reste disponible en fallback.

**Documentation complète**: Voir `docs/OPENAI_API_GPT5.md` pour détails complets, exemples de code, et références.
