# Technical Foundation (Existing Architecture)

### Architecture Overview

DialogueGenerator est un **projet brownfield production-ready** avec une architecture mature √©tablie. Les d√©cisions techniques document√©es ci-dessous constituent la **baseline architecturale** sur laquelle les features V1.0 s'appuieront.

**Source de v√©rit√© comportementale :** 18 Cursor rules (`.cursor/rules/*.mdc`) d√©finissent les patterns, conventions et contraintes pour les agents IA d√©veloppeurs.

### Stack Decisions (Already Made)

#### Frontend Architecture

**Technology Stack:**
- **React 18** + **TypeScript** + **Vite**
  - Rationale : Migration web termin√©e, production-ready, HMR performant
  - Pattern : Component-based SPA, composants r√©utilisables modulaires
- **Zustand** (State management)
  - Rationale : L√©ger, performant, moins verbeux que Redux
  - Usage : Auth, √©tat global, pas de prop drilling
- **React Flow 12** (Graph editor)
  - Rationale : SSR/SSG support, dark mode natif, reactive flows
  - Usage : Visualisation/√©dition graphes de dialogues (centaines n≈ìuds)
- **Vitest** + **React Testing Library** (Tests)
  - Rationale : Fast, compatible Vite, patterns modernes
  - Coverage : Tests unitaires composants + hooks

**Project Structure:**
```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/          # API client (axios + intercepteurs)
‚îÇ   ‚îú‚îÄ‚îÄ components/   # Composants React (layout, auth, generation)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/        # Custom hooks
‚îÇ   ‚îú‚îÄ‚îÄ store/        # Zustand stores
‚îÇ   ‚îú‚îÄ‚îÄ types/        # TypeScript types (align√©s Pydantic backend)
‚îÇ   ‚îî‚îÄ‚îÄ main.tsx      # Entry point
```

**Key Patterns:**
- API client modulaire par domaine (`auth.ts`, `dialogues.ts`, `interactions.ts`)
- Routes prot√©g√©es avec `ProtectedRoute`
- JWT en localStorage (access_token), refresh automatique
- Proxy API en dev (`vite.config.ts`), build production dans `dist/`

#### Backend Architecture

**Technology Stack:**
- **FastAPI** (Python 3.10+)
  - Rationale : Async/await natif, validation Pydantic, OpenAPI auto
  - Pattern : RESTful API, versioning `/api/v1/`
- **Pydantic** (Validation + models)
  - Rationale : Type safety, validation sch√©mas, g√©n√©ration JSON Schema
  - Usage : API DTOs, Unity dialogue models, structured outputs LLM
- **pytest** + **pytest-asyncio** (Tests)
  - Rationale : Standard Python, async support, fixtures puissantes
  - Coverage : >80% code critique (services, API)

**Project Structure:**
```
api/
‚îú‚îÄ‚îÄ routers/          # Routes HTTP (dialogues, config, logs, etc.)
‚îú‚îÄ‚îÄ schemas/          # Pydantic DTOs (request/response)
‚îú‚îÄ‚îÄ services/         # Adaptateurs API vers services m√©tier
‚îú‚îÄ‚îÄ dependencies.py   # Injection d√©pendances FastAPI
‚îú‚îÄ‚îÄ container.py      # ServiceContainer (cycle de vie services)
‚îî‚îÄ‚îÄ main.py           # Entry point

services/             # Logique m√©tier r√©utilisable
‚îú‚îÄ‚îÄ context/          # ContextBuilder, FieldValidator
‚îú‚îÄ‚îÄ prompt/           # PromptEngine, estimation tokens
‚îú‚îÄ‚îÄ llm/              # LLMClient (OpenAI, structured outputs)
‚îú‚îÄ‚îÄ json_renderer/    # UnityJsonRenderer
‚îî‚îÄ‚îÄ configuration/    # ConfigurationService
```

**Key Patterns:**
- **SOLID** : Routers = routes uniquement, Services API = adaptation, Services m√©tier = logique pure
- **Dependency Injection** : Via `api/container.py` (ServiceContainer), pas de singletons globaux
- **Service-oriented** : Logique dans `services/` (r√©utilisable API + tests)
- **Structured outputs** : Pydantic models ‚Üí JSON Schema ‚Üí LLM validation garantie

#### LLM Integration

**Technology Stack:**
- **Multi-Provider Support** (V1.0)
  - **OpenAI API** (GPT-5.2)
    - API : **Responses API** (`client.responses.create`) pour GPT-5.2
    - Contrainte : `reasoning.effort` incompatible avec `temperature`
    - Format : `input` (vs `messages`), `max_output_tokens`, tools plat
  - **Mistral API** (Small Creative) üÜï
    - API : **Chat Completions API** (`client.chat.completions.create`)
    - SDK : `mistralai` Python package
    - Streaming : Support natif via `stream=True`
    - Format : `messages` (role/content), `response_format` pour structured outputs
- **Structured Outputs**
  - Pattern : Pydantic ‚Üí `model_json_schema()` ‚Üí `response_model`
  - Garanties : Structure JSON, types corrects, conformit√© sch√©ma
  - Non-garanties : Logique m√©tier, formats sp√©cifiques (instructions prompt)
  - Multi-provider : Normalisation JSON Schema (OpenAI + Mistral)

**Key Patterns:**
- Abstraction `IGenerator` (interface) : Support multi-provider via factory pattern
- Factory : `LLMFactory.create(provider, model)` retourne client appropri√©
- Clients : `OpenAIClient` (existant), `MistralClient` üÜï (nouveau)
- Retry logic avec backoff exponentiel (par provider)
- Streaming avec gestion interruptions (V1.0, format SSE uniforme)
- Cost tracking et quotas (V1.0, diff√©renci√© par provider)

#### Data & Integration

**GDD (Game Design Document):**
- Source : Pipeline Notion externe (`main.py`/`filter.py` non modifi√©s)
- Chemin : Lien symbolique `data/GDD_categories/` + `import/Bible_Narrative/Vision.json`
- Contrainte : GDD externe, aucune modification pipeline

**Unity Export:**
- Format : JSON custom strict (mod√®les Pydantic `models/dialogue_structure/`)
- Contrainte : Pas de champs techniques expos√©s √† IA (`targetNode`, `nextNode`, etc.)
- Pattern : `enrich_with_ids()` ajoute champs techniques apr√®s g√©n√©ration

**Logs & Monitoring:**
- Format : JSON structur√© persistant (`data/logs/logs_YYYY-MM-DD.json`)
- Archivage : Rotation quotidienne + intra-jour (>100MB), 30j r√©tention
- API : `/api/v1/logs` (recherche, stats, nettoyage)

#### Testing Strategy

**Backend:**
- **pytest** : Tests unitaires + int√©gration, `TestClient` FastAPI (pas de serveur)
- **Mocks** : OpenAI, fichiers GDD, variables env (sauf `tmp_path`)
- **Coverage** : >80% code critique (services, API)
- **Commande** : `pytest tests/` ou `python -m pytest tests/`

**Frontend:**
- **Vitest** : Tests unitaires composants + hooks
- **React Testing Library** : Tests composants isol√©s
- **Playwright** : Tests E2E (auth, navigation, g√©n√©ration)
- **Commande** : `npm run test:frontend` (build + lint + tests)

#### Development Workflow

**Commands:**
- **Dev** : `npm run dev` (backend 4243 + frontend 3000 auto)
- **Dev debug** : `npm run dev:debug` (console DEBUG)
- **Dev clean** : `npm run dev:clean` (nettoie cache Vite)
- **Tests** : `pytest tests/` (backend) + `npm run test:frontend` (frontend)
- **Status** : `npm run dev:status` (health checks)

**Constraints Inherited:**
- **Windows-first** : PathLib, encodage UTF-8, pas d'hypoth√®ses POSIX
- **Cursor rules** : 18 fichiers `.mdc` = backbone comportemental agents IA

### Architectural Patterns Established

#### 1. Service Container Pattern (Dependency Injection)

**Location:** `api/container.py`

**Pattern:**
```python
class ServiceContainer:
    def __init__(self):
        self._context_builder = None
        self._prompt_engine = None
        # Lazy initialization, singleton lifecycle
    
    def get_context_builder(self) -> ContextBuilder:
        if not self._context_builder:
            self._context_builder = ContextBuilder()
        return self._context_builder
```

**Usage:** `api/dependencies.py` ‚Üí `get_context_builder()` ‚Üí inject√© dans routers

**Rationale:** Cycle de vie contr√¥l√©, testabilit√© (mocks), pas de singletons globaux

#### 2. Structured Outputs Pattern (LLM)

**Location:** `services/llm/`, `models/dialogue_structure/`

**Pattern:**
1. D√©finir mod√®le Pydantic (`UnityDialogueNode`)
2. G√©n√©rer JSON Schema (`model_json_schema()`)
3. Passer comme `response_model` au LLM client
4. Validation garantie par OpenAI (structure + types)

**Guarantees:** Structure JSON, types corrects, conformit√© sch√©ma  
**Non-Guarantees:** Logique m√©tier ‚Üí instructions prompt explicites

**Rationale:** Pas de parsing fragile, validation c√¥t√© LLM, robustesse

#### 3. Command + Memento Pattern (Undo/Redo)

**Status:** Pr√©vu V1.0 (state management layer)

**Pattern:**
- **Command** : Encapsule op√©rations (AddNode, DeleteNode, etc.)
- **Memento** : Capture √©tat avant op√©ration
- **Invoker** : G√®re historique commandes (undo/redo)

**Rationale:** Undo/Redo pour graph editor (centaines n≈ìuds)

#### 4. Multi-Layer Prompt Composition

**Location:** `services/prompt/prompt_engine.py`

**Pattern:**
- **Layer 1** : System prompt (format Unity, r√®gles RPG)
- **Layer 2** : Context (personnages, lieux, objets s√©lectionn√©s)
- **Layer 3** : Instructions sc√®ne (user input)

**Rationale:** Context management sophistiqu√©, √©vite "lore dropping", priorit√© claire

### Constraints & Technical Debt

**Known Bugs (Blockers V1.0):**
- **Graph editor** : DisplayName vs stableID (correction critique)
- **Pas de feedback g√©n√©ration** : UI "gel" pendant LLM (modal streaming V1.0)

**Technical Debt:**
- Pas d'auto-save (upgrade V1.0 : 2min intervals)
- Pas de presets (cold start friction, r√©solu V1.0)
- Validation structurelle basique (upgrade V1.0 : orphans, cycles)

**Limitations:**
- Multi-provider support√© (OpenAI + Mistral V1.0) ‚úÖ
- Pas de collaboration temps r√©el (V2.0+)
- Panneau D√©tails √©troit (340px, contraint pour feedback)

---
