# V1.0 Architectural Decisions (ADRs)

### ADR-001: Progress Feedback Modal (Streaming LLM)

**Context:**  
UI "gel" pendant g√©n√©ration LLM (30s+), pas de feedback utilisateur ‚Üí UX critique bloquante

**Decision:**  
Modal centr√©e avec streaming SSE (Server-Sent Events)

**Technical Design:**

**Frontend:**
- Nouveau composant `GenerationProgressModal.tsx`
- State : Zustand slice `useGenerationStore` (√©tat streaming)
- API : EventSource SSE vers `/api/v1/generate/stream`
- UI : 2 zones (sortie LLM stream + √©tapes/logs), 2 actions (Interrompre/R√©duire)

**Backend:**
- Nouveau router `/api/v1/generate/stream` (SSE endpoint)
- Pattern : `async def` generator avec `yield` (chunks SSE)
- LLM : `stream=True` sur `responses.create()` (GPT-5.2)
- Format : `data: {"type": "chunk", "content": "..."}\n\n`

**Constraints:**
- **DOIT** utiliser Zustand (pattern existant state management)
- **DOIT** respecter format SSE (`data: ...\n\n`)
- **NE DOIT PAS** modifier panneau D√©tails (trop √©troit, modal n√©cessaire)
- **DOIT** g√©rer interruption propre (AbortController frontend + cleanup backend)

**Rationale:**
- SSE > WebSocket (unidirectionnel, plus simple, fallback HTTP)
- Modal > panneau int√©gr√© (340px insuffisant, focus utilisateur)
- Streaming natif GPT-5.2 Responses API (pas de polling)

**Risks:**
- SSE timeout long g√©n√©ration (mitigation : keep-alive pings)
- Gestion erreurs stream interrompu (mitigation : error events SSE)

**Tests Required:**
- Unit : `useGenerationStore` state transitions
- Integration : `/api/v1/generate/stream` SSE format
- E2E : Modal affichage + interruption mid-stream

**Acceptance Criteria:**
- [ ] Modal visible d√®s clic "G√©n√©rer"
- [ ] Sortie LLM stream√©e en temps r√©el (<500ms latency)
- [ ] Bouton "Interrompre" arr√™te g√©n√©ration proprement
- [ ] Fermeture modal restaure UI pr√©c√©dente

---

### ADR-002: Presets syst√®me (Configuration sauvegarde/chargement)

**Context:**  
Cold start friction : 10+ clics pour premier dialogue (s√©lection personnages, lieux, instructions)

**Decision:**  
Syst√®me presets avec sauvegarde/chargement configurations compl√®tes

**Technical Design:**

**Data Model:**
```typescript
interface Preset {
  id: string;
  name: string;
  icon: string; // emoji
  metadata: {
    created: Date;
    modified: Date;
  };
  configuration: {
    characters: string[];      // IDs s√©lectionn√©s
    locations: string[];
    region: string;
    subLocation?: string;
    sceneType: string;         // "Premi√®re rencontre", etc.
    instructions: string;      // Brief sc√®ne
  };
}
```

**Frontend:**
- Nouveau composant `PresetBar.tsx` (barre compacte au-dessus "Sc√®ne Principale")
- 2 boutons : "üìã Charger preset ‚ñº" (dropdown) + "üíæ Sauvegarder preset"
- Modal sauvegarde : nom, ic√¥ne emoji, aper√ßu lecture seule
- State : Zustand slice `usePresetStore`

**Backend:**
- Nouveau router `/api/v1/presets` (CRUD)
- Storage : Fichiers JSON locaux `data/presets/{preset_id}.json`
- Service : `PresetService` (validation, persistence)

**Constraints:**
- **DOIT** capturer configuration compl√®te (personnages + lieux + instructions)
- **DOIT** valider IDs r√©f√©rences (personnages/lieux existent dans GDD)
- **NE DOIT PAS** stocker contenu GDD (seulement IDs)
- **DOIT** g√©rer preset obsol√®te (r√©f√©rences GDD supprim√©es)

**Rationale:**
- Cold start ‚Üí 1 clic (objectif efficiency V1.0)
- Stockage local (pas besoin DB, Git-friendly)
- Validation lazy (au chargement, pas √† la sauvegarde)

**Risks:**
- GDD updates rendent presets obsol√®tes (mitigation : validation chargement + warning)
- Synchronisation multi-utilisateurs (hors scope MVP, V2.0 RBAC)

**Tests Required:**
- Unit : `PresetService` validation + persistence
- Integration : API `/api/v1/presets` CRUD
- E2E : Workflow complet sauvegarde ‚Üí chargement ‚Üí g√©n√©ration

**Acceptance Criteria:**
- [ ] Bouton "Sauvegarder preset" capture configuration actuelle
- [ ] Modal sauvegarde : nom + ic√¥ne + aper√ßu
- [ ] Dropdown "Charger preset" liste presets disponibles
- [ ] Chargement preset restaure configuration compl√®te
- [ ] Warning si r√©f√©rences GDD invalides

---

### ADR-003: Graph Editor Fixes (DisplayName vs stableID)

**Context:**  
Bug critique : DisplayName utilis√© comme ID au lieu de stableID ‚Üí corruption graphe

**Decision:**  
Correction imm√©diate + tests r√©gression

**Technical Design:**

**Root Cause:**
- React Flow utilise `node.id` comme identifiant unique
- Code actuel : `node.id = displayName` (peut changer, collisions)
- Correct : `node.id = stableID` (UUID immuable)

**Fix:**
```typescript
// Avant (BUGGY)
const node = {
  id: dialogue.displayName,  // ‚ùå Mutable, collisions
  data: { ... }
};

// Apr√®s (CORRECT)
const node = {
  id: dialogue.stableID,      // ‚úÖ UUID immuable
  data: { 
    displayName: dialogue.displayName,  // Affich√© dans UI
    ...
  }
};
```

**Impact Analysis:**
- Fichiers : `frontend/src/components/graph/GraphEditor.tsx`
- Composants : Node rendering, edge connections
- State : Zustand store `useGraphStore`

**Constraints:**
- **DOIT** migrer donn√©es existantes (stableID manquants ‚Üí g√©n√©ration UUID)
- **NE DOIT PAS** casser graphes existants (backward compatibility)
- **DOIT** ajouter tests r√©gression (collision displayName)

**Rationale:**
- Stabilit√© identifiants = graphe robuste
- S√©paration ID technique (UUID) vs display (nom √©ditable)

**Risks:**
- Migration donn√©es existantes (mitigation : script migration + backup)
- Edge cases (n≈ìuds sans stableID) (mitigation : g√©n√©ration UUID automatique)

**Tests Required:**
- Unit : `generateStableID()` unicit√©
- Integration : Graph serialization/deserialization
- E2E : Renommer dialogue ne casse pas connexions

**Acceptance Criteria:**
- [ ] `node.id` utilise `stableID` (UUID)
- [ ] Renommer dialogue preserve connexions
- [ ] Aucun graphe existant corrompu apr√®s migration
- [ ] Tests r√©gression collisions displayName

---

### ADR-004: Multi-Provider LLM Support (Mistral Small Creative)

**Context:**  
Actuellement, DialogueGenerator utilise uniquement OpenAI GPT-5.2. Besoin d'ajouter Mistral Small Creative comme alternative s√©lectionnable pour offrir plus de flexibilit√© et r√©duire la d√©pendance √† un seul provider.

**Decision:**  
Impl√©menter abstraction multi-provider avec support OpenAI (GPT-5.2) + Mistral (Small Creative) en V1.0. Utilisateur peut s√©lectionner le mod√®le via UI.

**Technical Design:**

**Backend Abstraction:**
- Interface `IGenerator` existante √©tendue pour supporter multiple providers
- Nouveau service `services/llm/mistral_client.py` impl√©mentant `IGenerator`
- Factory pattern : `LLMFactory.create(provider: str, model: str)` retourne client appropri√©
- Configuration : `config/llm_config.json` d√©finit providers disponibles + mod√®les

**Provider-Specific Implementations:**
- **OpenAI** : `OpenAIClient` (existant, Responses API GPT-5.2)
- **Mistral** : `MistralClient` (nouveau, Chat Completions API, Small Creative)
  - SDK : `mistralai` Python package
  - Streaming : Support natif via `stream=True`
  - Structured outputs : Via `response_format` (JSON Schema)

**Frontend Model Selection:**
- Nouveau composant `components/generation/ModelSelector.tsx` (dropdown)
- State : Zustand `generationStore.selectedModel` (provider + model)
- Options affich√©es : "OpenAI GPT-5.2", "Mistral Small Creative"
- Persistence : Pr√©f√©rence sauvegard√©e dans localStorage

**API Changes:**
- Endpoint `/api/v1/generate/stream` accepte param√®tre `model` (optionnel, d√©faut: OpenAI)
- Format : `?provider=openai&model=gpt-5.2` ou `?provider=mistral&model=small-creative`
- Backward compatible : Si `model` absent, utilise OpenAI (comportement actuel)

**Constraints:**
- **DOIT** maintenir backward compatibility (OpenAI reste d√©faut)
- **DOIT** utiliser abstraction `IGenerator` (pas de code provider-sp√©cifique dans routers)
- **DOIT** supporter streaming pour tous providers (SSE format identique)
- **DOIT** g√©rer structured outputs pour tous providers (JSON Schema)
- **NE DOIT PAS** exposer diff√©rences providers √† l'utilisateur (abstraction compl√®te)

**Rationale:**
- **Flexibilit√©** : Utilisateur choisit mod√®le selon besoins (qualit√© vs co√ªt vs vitesse)
- **R√©duction d√©pendance** : Pas de vendor lock-in, fallback si OpenAI down
- **Cost optimization** : Mistral Small Creative potentiellement moins cher
- **Abstraction propre** : Pattern IGenerator d√©j√† en place, extension naturelle

**Risks:**
- **Diff√©rences API** : OpenAI Responses API vs Mistral Chat Completions (mitigation : abstraction IGenerator)
- **Structured outputs** : Formats diff√©rents (mitigation : normalisation JSON Schema)
- **Streaming** : Impl√©mentations diff√©rentes (mitigation : wrapper uniforme SSE)
- **Cost tracking** : Prix diff√©rents par provider (mitigation : cost service multi-provider)

**Tests Required:**
- Unit : `MistralClient` impl√©mente `IGenerator` correctement
- Unit : `LLMFactory` retourne bon client selon provider
- Integration : `/api/v1/generate/stream?provider=mistral` fonctionne
- Integration : Streaming Mistral produit format SSE identique
- E2E : S√©lection mod√®le dans UI ‚Üí g√©n√©ration avec bon provider

**Acceptance Criteria:**
- [ ] Dropdown "Mod√®le" dans UI g√©n√©ration
- [ ] S√©lection Mistral Small Creative ‚Üí g√©n√©ration fonctionne
- [ ] Streaming SSE identique pour OpenAI et Mistral
- [ ] Structured outputs fonctionnent pour les deux providers
- [ ] Cost tracking diff√©renci√© par provider
- [ ] Pr√©f√©rence mod√®le persist√©e (localStorage)

---

### ADR-005: RLM Context Selector (Autonomous Context Selection)

**Context:**  
S√©lection manuelle de contexte GDD est **cognitivement co√ªteuse et error-prone** :
- Sc√®ne "minimale" (2 personnages + 1 lieu) fait d√©j√† **15-20k tokens** en mode full
- Utilisateur doit d√©cider manuellement quelles fiches inclure et en quel mode (full/excerpt)
- Risque d'oublier √©l√©ments pertinents (liens cosmologiques, factions, objets rituels)
- Granularit√© trop grossi√®re : fiche "full" = 6-8k tokens, m√™me si seule une section est pertinente

**Probl√®me fondamental :** Avec des contextes de 20k+ tokens, m√™me avec fen√™tres 128k, les effets de d√©gradation OOLONG apparaissent (attention dilu√©e, d√©pendances longues brouill√©es, rappel pr√©cis d√©grad√©). Le vrai probl√®me n'est pas "comment choisir quelles fiches charger" mais **"comment raisonner sur un univers dont la sc√®ne active p√®se d√©j√† 20k tokens"**.

**Decision:**  
Impl√©menter une **couche optionnelle (on/off) de LLM "s√©lecteur autonome de contexte"** inspir√©e du paradigme **Recursive Language Models (RLM)** (arXiv:2512.24601) :
- Le syst√®me devient l'agent de s√©lection (exploration programmatique + d√©ductions)
- L'utilisateur devient superviseur (valide/ajuste, avec mode override)
- R√©duction contextuelle intelligente : 20k+ tokens ‚Üí 12-15k tokens sans perte de pertinence

**Technical Design:**

**Phase 1. Context Selection (RLM Agent)**

**Service Backend:**
```python
# services/rlm_context_selector.py
class RLMContextSelector:
    async def select_context(
        self,
        user_instructions: str,  # Instructions de Sc√®ne
        hints: Optional[Dict[str, List[str]]] = None,  # Optionnel : verrouiller √©l√©ments
        hints_mode: Optional[Dict[str, str]] = None,  # {"character_A": "full"}
        exclude: Optional[List[str]] = None,  # IDs √† exclure
        expansion_radius: int = 1,  # 0=aucune, 1=graphe direct, 2=indirect
        max_tokens_target: int = 15000,  # Budget global
        seed: Optional[int] = None,  # Reproductibilit√©
    ) -> ContextSelectionResult:
        # 1. Parse user_instructions pour extraire entit√©s explicites
        # 2. Exploration outill√©e (search_bm25, get_related, get_snippet, etc.)
        # 3. D√©ductions (liens cosmologiques, factions, objets rituels, etc.)
        # 4. D√©cision full/excerpt + section_filters pour chaque fiche
        # 5. Budget check (si d√©passement, passer plus en excerpt ou exclure)
        # 6. Retourner selected_elements + justifications + trace
```

**Outils GDD (expos√©s au LLM via function calling):**
```python
# Outils de navigation JSON
- get_node(id) -> json
- get_fields(id, fields[]) -> json
- list_ids(type=None, where_field_exists=None, limit=...)
- schema_overview() -> stats + exemples

# Outils de recherche
- search_bm25(query, top_k=20, filter_type=None) -> [{id, score, snippet}]
- search_regex(pattern, field=None, top_k=20) -> matches
- search_by_key_value(key, value, exact=True)

# Outils d'extraction contr√¥l√©e
- get_snippet(id, field, max_chars=2000, around=None)
- get_related(id, relation_keys=[...], depth=1)

# Outils d'agr√©gation
- count(filter...)
- group_by(field, filter...)
- build_table(ids, columns) -> rows
- diff(id_a, id_b, fields)
```

**Output Phase 1:**
```python
{
  "selected_elements": {
    "characters": {
      "Uresa√Ør": {
        "mode": "full",
        "section_filters": {
          "include": ["Psychologie", "Arc.Actuel", "Relations.Akthar"],
          "exclude": ["R√¥le cosmologique complet", "Histoire compl√®te"],
          "reason": "Focus sur dynamique relationnelle et √©tat √©motionnel"
        },
        "justification": {
          "reason": "hint_explicit",
          "proof": None
        }
      },
      "Akthar": {
        "mode": "full",
        "section_filters": {
          "include": ["Psychologie", "Relations.Uresa√Ør", "Croyances"],
          "exclude": ["R√¥le cosmologique complet"]
        },
        "justification": {
          "reason": "hint_explicit",
          "proof": None
        }
      }
    },
    "locations": {
      "Nef Centrale": {
        "mode": "full",
        "section_filters": {...},
        "justification": {
          "reason": "mentioned_explicitly",
          "proof": "Sc√®ne se d√©roule dans la Nef Centrale"
        }
      },
      "L√©viathan P√©trifi√©": {
        "mode": "excerpt",
        "justification": {
          "reason": "deduction_context_cosmologique",
          "proof": "L√©viathan mentionn√© comme cadre cosmologique dans Uresa√Ør.sections.R√¥le",
          "search_trace": ["get_related('Uresa√Ør')", "search_by_key_value('type', 'lieu_cosmologique')"]
        }
      }
    }
  },
  "trace": {
    "tools_called": ["search_bm25", "get_related", "get_snippet", ...],
    "decisions": [...],
    "total_tokens_estimated": 12000  # Optimis√© vs 20k+ en manuel
  }
}
```

**Phase 2. Context Build (inchang√© mais enrichi)**

**Integration avec ContextFieldManager:**
```python
# services/context_field_manager.py
def filter_fields_by_section_filters(
    self,
    element_type: str,
    fields_to_include: List[str],
    section_filters: Optional[Dict[str, List[str]]] = None  # <-- NOUVEAU
) -> List[str]:
    # Combine r√®gles statiques (context_config.json) + r√®gles dynamiques (section_filters)
    # Sans bypasser le DSL de champs existant
```

**Backend API:**
```python
# api/routers/context.py
@router.post("/select-context", response_model=SelectContextResponse)
async def select_context_auto(
    request_data: SelectContextRequest,
    rlm_selector: Annotated[RLMContextSelector, Depends(get_rlm_context_selector)],
) -> SelectContextResponse:
    # Phase 1 : RLM s√©lection automatique
    selection_result = await rlm_selector.select_context(
        user_instructions=request_data.user_instructions,
        hints=request_data.hints,
        ...
    )
    # Phase 2 : build_context_json (inchang√©)
    structured_context = context_builder.build_context_json(
        selected_elements=selection_result.selected_elements,
        scene_instruction=request_data.user_instructions,
        ...
    )
    return SelectContextResponse(
        selected_elements=selection_result.selected_elements,
        context=structured_context,
        trace=selection_result.trace
    )
```

**Frontend UI:**
- Toggle "Auto Selection" (on/off) dans panneau contexte
- Affichage "Contexte auto-s√©lectionn√©" avec justifications cliquables
- Mode "Override" : utilisateur peut forcer/ajouter des √©l√©ments m√™me en auto
- Mode "Lock" : utilisateur peut verrouiller certains √©l√©ments (toujours inclus)

**Constraints:**
- **DOIT** √™tre optionnel (on/off), avec fallback vers s√©lection manuelle
- **DOIT** rester compatible avec `ContextFieldManager`, `ContextTruncator`, `ContextSerializer`
- **NE DOIT PAS** bypasser `build_context_json()` (Option A, pas Option B)
- **DOIT** produire `selected_elements` avec `section_filters` enrichis
- **DOIT** inclure `justification` et `trace` pour tra√ßabilit√©
- **DOIT** respecter hints explicites (toujours inclus, mode full par d√©faut)
- **DOIT** √™tre reproductible (seed optionnel) ou au minimum tra√ßable
- **DOIT** g√©rer fallback gracieux (si RLM √©choue, retourner hints uniquement, pas d'erreur)

**Rationale:**
- **R√©duction friction** : Plus besoin de s√©lection manuelle laborieuse (10+ clics ‚Üí 1 clic "Auto")
- **Am√©lioration recall** : RLM trouve √©l√©ments pertinents que l'utilisateur aurait oubli√©s
- **Granularit√© adaptative** : S√©lection fine de sous-sections (ex: Uresa√Ør 6k ‚Üí 2-3k tokens) sans perte pertinence
- **Paradigme RLM** : Navigation programmatique du GDD, lecture r√©cursive, m√©moire de travail compacte, agr√©gation progressive
- **Compatible existant** : S'int√®gre proprement avec `ContextBuilder` sans casser invariants

**Risks:**
- **Non-d√©terminisme** : Agent peut choisir trajectoire diff√©rente (mitigation : seed + cache + tra√ßabilit√©)
- **S√©lection inattendue** : RLM peut inclure √©l√©ments non souhait√©s (mitigation : override + lock + exclusions)
- **Co√ªt LLM** : Exploration outill√©e = plusieurs appels LLM (mitigation : budget s√©par√© + cache + mod√®le "cheap" pour s√©lection)
- **Latence** : S√©lection automatique ajoute d√©lai avant g√©n√©ration (mitigation : cache + streaming progress)
- **Tests** : Agent loop difficile √† tester sans fixtures synth√©tiques (mitigation : tests avec mini-GDD + mocks LLM)

**Tests Required:**
- Unit : `RLMContextSelector.select_context()` avec mocks LLM
- Unit : `ContextFieldManager.filter_fields_by_section_filters()` combine r√®gles
- Integration : `/api/v1/context/select-context` avec vrai LLM (tests co√ªteux, limiter)
- Integration : Fallback gracieux si RLM √©choue
- E2E : Workflow complet auto-selection ‚Üí build_context ‚Üí g√©n√©ration

**Acceptance Criteria:**
- [ ] Toggle "Auto Selection" dans UI contexte
- [ ] RLM produit `selected_elements` avec `section_filters`
- [ ] Phase 2 `build_context_json()` utilise `section_filters` correctement
- [ ] R√©duction tokens : 20k+ ‚Üí 12-15k sans perte pertinence
- [ ] Justifications affich√©es (utilisateur peut comprendre pourquoi √©l√©ment inclus)
- [ ] Mode override fonctionne (ajout/force √©l√©ments m√™me en auto)
- [ ] Fallback gracieux si RLM √©choue (pas d'erreur, retourne hints uniquement)
- [ ] Tra√ßabilit√© compl√®te (trace contient trajectoire agent)

**Open Questions:**
- Mod√®le LLM pour s√©lection ? (GPT-5-mini pour co√ªt vs GPT-5.2 pour qualit√©)
- Budget exploration ? (5-10k tokens max pour phase 1 vs budget global g√©n√©ration)
- Cache s√©lections ? (m√™me `user_instructions` + `hints` = r√©sultat identique)
- Section filters granularit√© ? (niveau champ vs niveau sous-section vs niveau paragraphe)

---

### ADR-006: Autosave imm√©diat, z√©ro perte, seq + atomique (Graph Editor)

**Context:**  
Auto-save actuel : debounce 1,2 s, pas de journal local, √©criture fichier directe. Risques : perte √† la fermeture d‚Äôonglet/crash, fichier JSON tronqu√© si crash pendant write, requ√™tes r√©ordonn√©es peuvent √©craser un √©tat plus r√©cent. Contrainte UX : d√©lai max 0,1 s acceptable, 1,2 s non.

**Decision:**  
Store = document (une seule source de v√©rit√© en m√©moire). Pas de mode draft/save ; tout est ‚Äúenregistr√©‚Äù localement et synchronis√©. R√©silience : journal local IndexedDB + seq monotone c√¥t√© client/serveur + √©criture atomique c√¥t√© serveur (tmp ‚Üí fsync ‚Üí rename). Micro-batch envoi 100 ms max.

**Technical Design:**

**Frontend:**
- √Ä chaque modification : mutation dans le store **en premier** (aucune exception), puis append dans journal IndexedDB (par documentId), puis envoi vers serveur en micro-batch 100 ms (ou imm√©diat selon option).
- **Pas de brouillon dans les formulaires** : les champs √©ditables (panneau D√©tails : speaker, line, choix, etc.) doivent pousser vers le store √† la saisie (debounce court ‚â§ 100 ms ou imm√©diat). Un flush uniquement au changement de n≈ìud ou au blur est **non conforme** ‚Äî fermeture d‚Äôonglet ou crash sans quitter le n≈ìud entra√Ænerait une perte.
- Journal IndexedDB : scope par document (documentId = filename ou id stable). Contenu : dernier snapshot apr√®s ack + queue des mutations non ack√©es (ou dernier √©tat complet en attente). Au chargement : dernier snapshot + pending, puis sync avec serveur (seq).
- Chaque envoi porte un **seq** monotone (client-assign√©, incr√©ment√© √† chaque envoi).
- UI statut : ‚ÄúSynced (seq ‚Ä¶)‚Äù / ‚ÄúOffline, N changes queued‚Äù / ‚ÄúError‚Äù ; pas de bouton ‚ÄúSauvegarder‚Äù ; optionnel ‚ÄúSynchroniser maintenant‚Äù.

**Backend:**
- Requ√™te contient **seq** (optionnel en v1 pour r√©trocompat : si absent, appliquer sans garde-fou).
- Serveur conserve **last_seq** par document (persist√© en fichier sidecar ou en base pour survivre au red√©marrage).
- R√®gles : **seq ‚â§ last_seq** ‚Üí ignorer (r√©ponse 200 + ack(last_seq)) ; **seq > last_seq** ‚Üí appliquer payload, persister, **last_seq = seq**, r√©pondre **ack(seq)**.
- Persistance fichier : √©crire dans **file.tmp**, fsync, rename atomique **file.tmp** ‚Üí **file.json**. Optionnel : **file.prev.json** (N-1) pour recovery.

**Constraints:**
- **DOIT** garantir d√©lai per√ßu ‚â§ 0,1 s (micro-batch 100 ms max).
- **DOIT** √©viter perte √† fermeture onglet/crash/navigation (journal IndexedDB).
- **DOIT** √©viter fichier tronqu√© (√©criture atomique serveur).
- **DOIT** √©viter qu‚Äôun envoi ancien √©crase un r√©cent (seq / last_seq).
- **NE DOIT PAS** conserver de brouillon dans les formulaires : toute modification √©ditable doit √™tre pouss√©e vers le store (debounce ‚â§ 100 ms ou imm√©diat), puis journal + sync. **Aucune exception** ‚Äî flush uniquement au changement de n≈ìud ou au blur = non conforme.
- **NE DOIT PAS** introduire co-√©dition (multi-onglets non garanti ; documenter).

**Rationale:**
- Seq + last_seq = garde-fou minimal sans OT/CRDT.
- IndexedDB = r√©silience locale sans d√©pendre au blur.
- Atomic write = pratique standard (tmp + rename) sur Windows/Linux.

**Risks:**
- Persistance last_seq c√¥t√© serveur (mitigation : sidecar ou fichier par document).
- Identit√© document stable (documentId) partag√©e front/back (mitigation : filename ou id d√©riv√©).

**Tests Required:**
- Unit : journal IndexedDB (√©criture/replay), seq incr√©ment, micro-batch 100 ms.
- Integration : API save-and-write avec seq / last_seq, √©criture atomique (tmp ‚Üí rename).
- E2E : modification ‚Üí fermeture onglet ‚Üí r√©ouverture ‚Üí √©tat restaur√© ; statut Synced/Offline/Error.

**Acceptance Criteria:**
- [ ] Store = document ; pas de bouton ‚ÄúSauvegarder‚Äù.
- [ ] Aucun brouillon dans les formulaires : speaker, line, choix, etc. pouss√©s vers le store (debounce ‚â§ 100 ms ou imm√©diat) ; pas de flush uniquement au changement de n≈ìud.
- [ ] D√©lai regroupement ‚â§ 100 ms (pas 1,2 s).
- [ ] Journal IndexedDB par document ; rechargement = dernier snapshot + pending puis sync.
- [ ] Serveur : seq ‚â§ last_seq ‚Üí ignore ; seq > last_seq ‚Üí applique, √©criture atomique, ack(seq).
- [ ] UI : ‚ÄúSynced (seq ‚Ä¶)‚Äù / ‚ÄúOffline, N changes queued‚Äù / ‚ÄúError‚Äù.

**R√©f√©rence sp√©cification d√©taill√©e :** sp√©cification consolid√©e ‚Äúautosave imm√©diat, z√©ro perte, seq + atomique‚Äù (principes, protocole serveur, journal local, micro-batching, UI statut).

---

### ADR-007: React Flow en mode controlled (source unique nodes/edges)

**Context:**  
Le canvas graphe utilise aujourd'hui les hooks React Flow `useNodesState` / `useEdgesState` : l'√©tat affich√© est g√©r√© en interne par React Flow, le store Zustand sert √† la persistance et √† la logique m√©tier. Cette double source de v√©rit√© (√©tat RF + store) provoque des d√©synchronisations (√©tiquettes qui scintillent, liens qui disparaissent au clic), des correctifs fragiles (comparaisons, refs de stabilisation) et emp√™che une coh√©rence fiable pour l'autosave, l'undo/redo, la synchro serveur et la collaboration future.

**Decision:**  
React Flow est utilis√© en **mode controlled** : les `nodes` et `edges` pass√©s au composant `<ReactFlow>` proviennent **uniquement** du store Zustand (graphStore). Aucun √©tat local pour nodes/edges dans le canvas (pas de `useNodesState` / `useEdgesChange`). Les handlers `onNodesChange` et `onEdgesChange` ne font qu'appeler des actions du store. Le **viewport** (zoom, pan, position de la cam√©ra) reste en √©tat **local** √† React Flow (non persist√©, hors store document).

**Technical Design:**

**Frontend (GraphCanvas / couche graphe) :**
- **Source des props** : `nodes` et `edges` sont d√©riv√©s du store (ex. `useGraphStore()` ‚Üí `storeNodes`, `storeEdges`), enrichis si besoin (validation, highlight) via `useMemo` √† partir du store, puis pass√©s tels quels √† `<ReactFlow nodes={‚Ä¶} edges={‚Ä¶} />`.
- **Handlers** : `onNodesChange` et `onEdgesChange` appliquent **tous** les types de changement (position, dimension, remove, **select**, etc.) **uniquement** via des actions du store (ex. `updateNodePosition`, `deleteNode`, `setSelectedNode`, etc.). Les changements de type **`select`** dans `onNodesChange` doivent mettre √† jour le store (pas seulement `onNodeClick`), afin qu'aucune s√©lection ne reste uniquement dans l'√©tat interne de React Flow. Utiliser `applyNodeChanges` / `applyEdgeChanges` c√¥t√© store ou dans les handlers pour produire le nouvel √©tat, puis `setState` store ‚Äî jamais de `setNodes` / `setEdges` local.
- **S√©lection** : La s√©lection (n≈ìud(s) s√©lectionn√©(s)) vit dans le store (ex. `selectedNodeId` / `selectedNodeIds`). Les `nodes` pass√©s √† React Flow refl√®tent cette s√©lection (ex. `node.selected = (node.id === selectedNodeId)`). Les changements de s√©lection dans `onNodesChange` (type `select`) mettent √† jour le store.
- **Viewport** : Non stock√© dans le store. React Flow g√®re zoom/pan en interne ; pas de persistance viewport exig√©e par cette ADR.
- **Compatibilit√© React Flow** : Respecter le pattern "controlled" document√© (React Flow : parent state + `onNodesChange` / `onEdgesChange` mettent √† jour ce state). Le conteneur parent doit avoir une largeur et une hauteur d√©finies ; la feuille de style React Flow doit √™tre import√©e.

**P√©rim√®tre :**
- ADR-007 s'applique au canvas **√©diteur** (GraphCanvas). Le composant **GraphView** (vue read-only, source = prop `json_content`, pas de graphStore) est hors p√©rim√®tre : il peut rester en mode uncontrolled ou √™tre migr√© en controlled avec √©tat parent d√©riv√© des props ; le choix est laiss√© √† l'impl√©mentation tant qu'il n'y a pas de persistance ni de double source de v√©rit√©.

**Constraints:**
- **DOIT** avoir une seule source de v√©rit√© pour les nodes et edges affich√©s : le store (graphStore).
- **NE DOIT PAS** utiliser `useNodesState` ni `useEdgesState` (ni √©quivalent √©tat local pour nodes/edges) dans le composant qui rend `<ReactFlow>` pour l'√©diteur de graphe.
- **DOIT** faire en sorte que tout changement utilisateur (drag, clic, connexion, suppression) remonte au store via `onNodesChange` / `onEdgesChange` / `onConnect`, sans mise √† jour d'un √©tat local nodes/edges.
- **DOIT** garder le viewport (zoom/pan) en √©tat local √† React Flow (pas dans le store document).
- **DOIT** refl√©ter la s√©lection affich√©e depuis le store (pas d'√©tat de s√©lection uniquement interne √† React Flow pour les n≈ìuds/edges document).

**Rationale:**
- Alignement avec ADR-006 : le store est d√©j√† la source de v√©rit√© du document ; le canvas doit en √™tre une vue stricte.
- Autosave, undo/redo, synchro serveur et future collaboration reposent sur un √©tat document unique et pr√©visible.
- Suppression des bugs de sync (scintillement, disparition d'edges) et du code de contournement (refs, comparaisons "position seule").
- **Export PNG/SVG** : en mode controlled, l'instance React Flow refl√®te le store ; l'export visuel refl√®te donc l'√©tat document.
- **Undo/redo (zundo)** : la restauration du store suffit ; l'affichage suit automatiquement car le canvas est pilot√© par le store.

**Risks:**
- Performance pendant le drag : chaque mouvement peut d√©clencher une mise √† jour du store et un re-render. Mitigation : mises √† jour store l√©g√®res (ex. uniquement positions) ; debounce/throttle d√©j√† en place pour la persistance (journal/API) ; si besoin, throttler les appels `updateNodePosition` pendant le drag (ex. `requestAnimationFrame`).

**Tests Required:**
- R√©gression : apr√®s clic sur un n≈ìud, les edges restent visibles et coh√©rents.
- R√©gression : apr√®s drag d'un n≈ìud, les positions dans le store correspondent √† l'affichage.
- Unitaire / int√©gration : s√©lection mise √† jour dans le store lors des √©v√©nements de s√©lection React Flow.
- Optionnel : E2E "√©dition ‚Üí refresh / reload ‚Üí √©tat restaur√©" (d√©j√† couvert par ADR-006 ; controlled n'ajoute pas de perte).

**Acceptance Criteria:**
- [ ] Les `nodes` et `edges` pass√©s √† `<ReactFlow>` proviennent exclusivement du store (ou de d√©rivations du store, ex. enrichissement validation/highlight).
- [ ] Aucun `useNodesState` / `useEdgesState` dans le composant principal du canvas graphe (√©diteur).
- [ ] `onNodesChange` et `onEdgesChange` ne mettent √† jour que le store (via actions graphStore).
- [ ] La s√©lection affich√©e (n≈ìud s√©lectionn√©) est lue depuis le store et les changements de s√©lection mettent √† jour le store. Tout changement de s√©lection (clic, multi-select, programmatique) met √† jour le store via `onNodesChange` ou handlers d√©di√©s.
- [ ] Le viewport (zoom/pan) n'est pas persist√© dans le store document.
- [ ] Aucune r√©gression : edges visibles apr√®s clic sur un n≈ìud ; pas de scintillement des √©tiquettes lors du drag (avec optimisations si besoin).

**R√©f√©rence :** React Flow "controlled" pattern (√©tat dans le parent, handlers mettent √† jour cet √©tat) ; doc projet `docs/architecture/state-management-frontend.md`, `docs/architecture/graph-conversion-architecture.md`.

---

### ADR-008: Pipeline document canonique Unity JSON (Backend propri√©taire, SoT document, choiceId, layout partag√©)

**Context:**  
Le pipeline actuel (Unity ‚áÑ Backend Python ‚áÑ Front React Flow) a √©volu√© avec une SoT en m√©moire = nodes/edges (store) et une conversion backend (JSON ‚Üí graphe au load, graphe ‚Üí JSON au save). Le stakeholder exige que le **document canonique** soit le **Unity Dialogue JSON** partout ; le backend doit en √™tre le propri√©taire ; le frontend ne doit plus envoyer nodes/edges mais le document ; les identit√©s (choiceId) doivent √™tre stables pour √©viter les bugs de mapping et de r√©ordonnancement. Une revue architecte consultant externe a produit une recommandation consolid√©e ; six d√©cisions associ√©es ont √©t√© valid√©es (propri√©taire document, layout partag√©, schemaVersion, Unity, refus sans choiceId, cible perf).

**Decision:**  
Un seul **format de document canonique** partag√© par tout le pipeline : **Unity Dialogue JSON** (sch√©ma v1.1.0), valid√©/normalis√© de fa√ßon coh√©rente, projet√© en UI (React Flow) sans devenir une seconde source de v√©rit√©. Le **backend** poss√®de le document (source canonique, persistance, revision, arbitrage des conflits). Le **frontend** est un client √©diteur ; **Unity** est un consommateur/√©diteur du m√™me format. Le document inclut `schemaVersion` (ex. 1.1.0) et `choices[].choiceId` (requis, identit√© stable). Le **layout** (positions, zoom) est un artefact distinct, **partag√©** par document, persist√© c√¥t√© backend (ex. sidecar), soumis aux m√™mes r√®gles de concurrence. L‚ÄôAPI parle uniquement en ¬´ document canonique ¬ª (et layout si applicable) : pas d‚Äô√©change nodes/edges ; endpoints type GET/PUT par document (path|id) avec `revision` pour contr√¥le de concurrence. La validation distingue ¬´ draft ¬ª (non bloquant, autosave autoris√©) et ¬´ export ¬ª (bloquant). Migration : outil one-shot pour ajouter `choiceId` aux documents existants ; lecture tol√©rante courte ; √† partir de `schemaVersion >= 1.1.0`, l‚Äôabsence de `choiceId` est refus√©e.

**Technical Design:**

**Mod√®le de donn√©es :**
- Document : Unity Dialogue JSON v1.1.0 avec `schemaVersion` requis, `choices[].choiceId` requis (format libre, stable). `node.id` reste SCREAMING_SNAKE_CASE. Pseudo-n≈ìud END document√© si r√©f√©renc√©.
- Layout : artefact s√©par√© (ex. `*.layout.json` ou √©quivalent), m√™me r√®gles de revision/concurrence que le document.

**Backend :**
- Valide et normalise le document sans casser `choiceId`, ordre des `choices[]`, `node.id`. Ne reconstruit plus un document √† partir d‚Äôun graphe UI.
- Endpoints (cible P0) : GET /documents/{path|id} ‚Üí { document, schemaVersion, revision } ; PUT /documents/{path|id} avec payload { document, revision } ‚Üí { revision, validationReport }. Conflit ‚Üí 409 + dernier √©tat.

**Frontend :**
- SoT contenu = `document` (Unity JSON) ; SoT layout = `layout`. Nodes/edges = projection d√©riv√©e uniquement.
- Identit√©s UI stables : node id = `node.id` ; choice handle = `choice:${choiceId}` ; TestNode id = `test:${choiceId}` ; edge ids bas√©s sur la sortie (ex. `e:${nodeId}:choice:${choiceId}:target`), jamais sur la destination seule.
- Saisie : form local + debounce/throttle/blur inchang√© ; la projection ne doit pas provoquer de reset du panel.

**Unity :**
- DTO √©tendus pour inclure `choiceId` (et tout champ requis) ; s√©rialisation/normalisation pr√©servent ces champs (pas de perte JsonUtility).

**D√©cisions associ√©es (hypoth√®ses valid√©es) :**
1. Backend = propri√©taire du document (source canonique, revision, conflits).
2. Layout = partag√© par document, persist√© backend, m√™me concurrence.
3. `schemaVersion` dans le JSON ; s√©mantique partag√©e frontend/backend/Unity.
4. Unity ne perd aucun champ (m√™me format strict, DTO align√©s).
5. Refus document sans `choiceId` conditionn√© par `schemaVersion >= 1.1.0` ; migration one-shot puis format courant uniquement.
6. Cible perf : plusieurs milliers de n≈ìuds ; tests avec borne confort/stress et r√®gles m√©tier (4 choix cin√©ma, 8+ hors cin√©ma).

**Constraints:**
- Le frontend NE DOIT PLUS envoyer nodes/edges au backend pour le save ; il envoie le document (et optionnellement le layout).
- Le backend NE DOIT PAS reconstruire le document √† partir d‚Äôun graphe UI ; il valide/normalise le document re√ßu.
- Toute identit√© √©ditable/liaisonnable (choice, etc.) DOIT avoir un identifiant stable (choiceId) ; pas d‚Äôindex seul comme identit√© durable pour les edges/handles.

**Rationale:**
- Alignement avec l‚Äôexigence stakeholder ¬´ JSON = source de v√©rit√© ¬ª et avec la revue consultant.
- Une seule source canonique (document) √©vite les d√©rives et les doubles conversions.
- Identit√©s stables (choiceId) √©vitent les bugs de s√©lection, focus, drag, undo et les r√©gressions ¬´ √ßa dispara√Æt / √ßa saute ¬ª.

**Risks:**
- Migration des documents existants (fichiers, fixtures) : att√©nuation par outil one-shot + lecture tol√©rante courte.
- Changement de contrat API (load/save) et refactor store frontend : plan d‚Äôimpl√©mentation par epics/stories.

**Tests Required:**
- Golden : JSON ‚Üí projection nodes/edges avec IDs stables, edgeIds stables ; changement de cible ‚Üí edgeId inchang√©.
- E2E : √©dition line/speaker/choice sans perte ; connecter/d√©connecter ; dupliquer n≈ìud (nouveaux node.id et choiceId, refs effac√©es) ; reload avec layout.
- Perf : cible confort + borne stress (milliers de n≈ìuds, 4/8 choices selon m√©tier), p95 frappe/drag/load sans n≈ìuds invisibles.

**R√©f√©rence :** Document de synth√®se architecte consultant + 6 d√©cisions associ√©es (√† d√©poser dans `docs/architecture/`, ex. `pipeline-unity-backend-front-architecture.md`). Processus de validation et mise en place : `docs/architecture/validation-et-mise-en-place-decisions.md`.

---

### Integration Patterns (V1.0 ‚Üî Baseline)

#### Pattern 1: New API Endpoints (Streaming, Presets)

**Integration:**
- Nouveau router dans `api/routers/` (ex: `streaming.py`, `presets.py`)
- Enregistrement dans `api/main.py` : `app.include_router(streaming_router)`
- Service backend dans `services/` si logique m√©tier (ex: `PresetService`)
- Tests dans `tests/api/test_<router>.py`

**Follows Baseline:**
- ‚úÖ RESTful conventions (`/api/v1/*`)
- ‚úÖ Pydantic schemas (`api/schemas/`)
- ‚úÖ Dependency injection (`api/dependencies.py`)
- ‚úÖ Error handling (exceptions hi√©rarchis√©es)

#### Pattern 2: New React Components (Modal, PresetBar)

**Integration:**
- Nouveaux composants dans `frontend/src/components/<domain>/`
- State management via Zustand (nouveaux slices si n√©cessaire)
- API calls via `frontend/src/api/<domain>.ts`
- Tests dans `frontend/src/components/<domain>/<Component>.test.tsx`

**Follows Baseline:**
- ‚úÖ TypeScript strict
- ‚úÖ Zustand pour state global
- ‚úÖ API client modulaire (axios + intercepteurs)
- ‚úÖ Tests unitaires (Vitest + RTL)

#### Pattern 3: Graph Editor Fixes (Refactoring)

**Integration:**
- Modifications dans `frontend/src/components/graph/`
- Migration donn√©es si n√©cessaire (script `scripts/migrate-stableIDs.ts`)
- Tests r√©gression dans `frontend/src/components/graph/GraphEditor.test.tsx`

**Follows Baseline:**
- ‚úÖ Pas de breaking changes API
- ‚úÖ Backward compatibility (migrations gracieuses)
- ‚úÖ Tests couvrent edge cases

---

