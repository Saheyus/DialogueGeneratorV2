### Epic 1: Am√©lioration et peaufinage de la g√©n√©ration de dialogues

**Objectif :** Am√©liorer l'exp√©rience utilisateur et la robustesse de la g√©n√©ration de dialogues existante.

**Contexte :** La g√©n√©ration de dialogues assist√©e par IA est d√©j√† fonctionnelle (g√©n√©ration single/batch, √©dition manuelle, auto-link). Cet Epic se concentre sur les am√©liorations qui r√©duisent la friction dans le workflow et donnent plus de contr√¥le √† l'utilisateur.

**Valeur utilisateur :** R√©duire la friction dans le workflow de g√©n√©ration, am√©liorer la qualit√© des dialogues g√©n√©r√©s, et donner plus de contr√¥le √† l'utilisateur sur l'it√©ration et l'optimisation.

**FRs covered:** FR1-10 (g√©n√©ration, √©dition, auto-link, r√©g√©n√©ration), FR72-79 (estimation co√ªts, logs, fallback provider)

**NFRs covered:** NFR-P2 (LLM Generation <30s single, <2min batch), NFR-I2 (LLM API Reliability >99%), NFR-R4 (Error Recovery LLM >95%)

**D√©pendances:** Epic 0 (infrastructure), Epic 3 (contexte GDD requis pour g√©n√©ration)

**Statut des US :**
- ‚úÖ **DONE (8)** : US 1.1, 1.2, 1.3, 1.5, 1.8, 1.9, 1.13
- üî¥ **PRIORIT√â A - Critiques (3)** : US 1.4, 1.6, 1.10
- üü° **PRIORIT√â B - Importantes (3)** : US 1.7, 1.11, 1.15
- üü¢ **PRIORIT√â C - Nice-to-have (3)** : US 1.12, 1.14, 1.16

---

## ‚ö†Ô∏è GARDE-FOUS - V√©rification de l'Existant (Scrum Master)

**OBLIGATOIRE avant cr√©ation de chaque story de cet epic :**

### Checklist de V√©rification

1. **Fichiers mentionn√©s dans les stories :**
   - [ ] V√©rifier existence avec `glob_file_search` ou `grep`
   - [ ] V√©rifier chemins corrects (ex: `core/llm/` vs `services/llm/`)
   - [ ] Si existe : **D√âCISION** - √âtendre ou remplacer ? (documenter dans story)

2. **Composants/Services similaires :**
   - [ ] Rechercher composants React similaires (`codebase_search` dans `frontend/src/components/`)
   - [ ] Rechercher stores Zustand similaires (`codebase_search` dans `frontend/src/store/`)
   - [ ] Rechercher services Python similaires (`codebase_search` dans `services/`, `core/`)
   - [ ] Si similaire existe : **D√âCISION** - R√©utiliser ou cr√©er nouveau ? (documenter dans story)

3. **Endpoints API :**
   - [ ] V√©rifier namespace coh√©rent (`/api/v1/dialogues/*` vs autres)
   - [ ] V√©rifier si endpoint similaire existe (`grep` dans `api/routers/`)
   - [ ] Si endpoint similaire : **D√âCISION** - √âtendre ou cr√©er nouveau ? (documenter dans story)

4. **Patterns existants :**
   - [ ] V√©rifier patterns Zustand (immutable updates, structure stores)
   - [ ] V√©rifier patterns FastAPI (routers, dependencies, schemas)
   - [ ] V√©rifier patterns React (composants, hooks, modals)
   - [ ] Respecter conventions de nommage et structure dossiers

5. **Documentation des d√©cisions :**
   - Si remplacement : Documenter **POURQUOI** dans story "Dev Notes"
   - Si extension : Documenter **COMMENT** (quels champs/m√©thodes ajouter)
   - Si nouveau : Documenter **POURQUOI** pas de r√©utilisation

---

### Story 1.1: G√©n√©rer un n≈ìud de dialogue single depuis un n≈ìud parent dans le graphe (FR1)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√† compl√®tement. Cette US sert de documentation de r√©f√©rence.
- ‚úÖ Endpoint `/api/v1/unity-dialogues/graph/generate-node` impl√©ment√©
- ‚úÖ Composant `AIGenerationPanel.tsx` avec toutes les fonctionnalit√©s
- ‚úÖ Contexte parent int√©gr√©, streaming, auto-layout, auto-link

As a **utilisateur cr√©ant des dialogues dans le graphe**,
I want **g√©n√©rer un n≈ìud de dialogue unique depuis un n≈ìud parent existant avec assistance LLM**,
So that **je peux it√©rer rapidement sur la cr√©ation de dialogues en construisant le graphe n≈ìud par n≈ìud**.

**Acceptance Criteria:**

**Given** j'ai un dialogue ouvert dans l'√©diteur de graphe avec au moins un n≈ìud existant
**When** je s√©lectionne un n≈ìud parent et clique sur "‚ú® G√©n√©rer n≈ìud IA"
**Then** le modal `AIGenerationPanel` s'ouvre avec le contexte du n≈ìud parent (speaker + line tronqu√©e)
**And** je peux s√©lectionner un choix sp√©cifique du parent ou laisser libre
**And** je peux saisir des instructions optionnelles (tone, style, theme)

**Given** j'ai configur√© la g√©n√©ration (choix cible + instructions optionnelles)
**When** je clique sur "‚ú® G√©n√©rer"
**Then** un n≈ìud de dialogue est g√©n√©r√© avec texte, speaker, et choix (si applicable)
**And** le n≈ìud appara√Æt dans le graphe avec un stableID unique
**And** la g√©n√©ration se termine en <30 secondes (NFR-P2)

**Given** je lance une g√©n√©ration single depuis le graphe
**When** la g√©n√©ration est en cours
**Then** la modal de progression (Epic 0 Story 0.2) affiche le streaming en temps r√©el
**And** je peux interrompre la g√©n√©ration si n√©cessaire

**Given** la g√©n√©ration r√©ussit
**When** le n≈ìud est cr√©√© dans le graphe
**Then** le n≈ìud est automatiquement positionn√© visuellement (auto-layout)
**And** le n≈ìud est automatiquement li√© au n≈ìud parent si un choix a √©t√© s√©lectionn√© (auto-link, voir Story 1.9)
**And** je peux accepter ou rejeter le n≈ìud (voir Story 1.4)

**Given** je sp√©cifie des instructions de g√©n√©ration (tone, style, theme)
**When** le n≈ìud est g√©n√©r√©
**Then** le n≈ìud respecte les instructions (tone coh√©rent, style demand√©, theme pr√©sent)
**And** les instructions sont incluses dans le prompt LLM avec le contexte du n≈ìud parent

**Technical Requirements:**
- Backend : Endpoint `/api/v1/unity-dialogues/graph/generate-node` (existant, √† consolider)
  - Utilise `UnityDialogueOrchestrator` qui coordonne les services
  - Service : `UnityDialogueGenerationService.generate_dialogue_node()` avec Structured Output
  - Int√®gre le contexte du n≈ìud parent dans le prompt (speaker + line + choix si applicable)
- LLM : Utilise provider s√©lectionn√© (OpenAI/Mistral via Epic 0 Story 0.3)
- Frontend : 
  - Composant `AIGenerationPanel.tsx` (existant, √† am√©liorer) : Modal de g√©n√©ration depuis graphe
  - Composant `GenerationPanel.tsx` : G√©n√©ration standalone (hors scope de cette story)
- Integration : Epic 0 Story 0.2 (Progress Modal) pour feedback streaming
- Auto-layout : Positionnement automatique du nouveau n≈ìud dans le graphe (React Flow)
- Tests : Unit (g√©n√©ration n≈ìud avec contexte parent), Integration (API g√©n√©ration graphe), E2E (workflow complet depuis graphe)

**Dev Notes:**
- **Diff√©rence avec g√©n√©ration standalone :** La g√©n√©ration depuis le graphe utilise le contexte du n≈ìud parent (speaker, line, choix) pour cr√©er une continuit√© narrative. La g√©n√©ration standalone (`GenerationPanel.tsx`) g√©n√®re un n≈ìud isol√© sans contexte de graphe.
- **Architecture :** L'endpoint utilise `UnityDialogueOrchestrator` qui orchestre plusieurs services (prompt building, LLM generation, cost tracking). Ne pas appeler directement `UnityDialogueGenerationService` depuis l'endpoint.
- **D√©pendances :** Story 1.4 (accept/reject) et Story 1.9 (auto-link) sont des am√©liorations qui s'appliquent apr√®s la g√©n√©ration. Cette story se concentre sur la g√©n√©ration elle-m√™me.

**References:** FR1 (g√©n√©ration single), FR3 (instructions), NFR-P2 (LLM Generation <30s), Epic 0 Story 0.2 (Progress Modal)

---

### Story 1.2: G√©n√©rer batch de n≈ìuds depuis tous les choix existants (FR2)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√†. Cette US sert de documentation de r√©f√©rence.
- ‚úÖ Endpoint avec `generate_all_choices=True` impl√©ment√©
- ‚úÖ Service `GraphGenerationService` avec g√©n√©ration parall√®le
- ‚úÖ Frontend avec bouton "‚ú® G√©n√©rer pour tous les choix"
- ‚úÖ Progression batch dans la modal
- ‚ö†Ô∏è Am√©liorations possibles : gestion des √©checs partiels, interruption batch (peuvent √™tre dans des US futures)

As a **utilisateur cr√©ant des dialogues dans le graphe**,
I want **g√©n√©rer automatiquement un n≈ìud pour chaque choix non connect√© d'un n≈ìud parent en une seule requ√™te**,
So that **je peux cr√©er rapidement des branches de dialogue compl√®tes sans g√©n√©rer chaque n≈ìud individuellement**.

**Acceptance Criteria:**

**Given** j'ai un n≈ìud avec des choix joueur (ex: "Accepter", "Refuser", "Questionner") dont certains n'ont pas de `targetNode` (ou `targetNode === "END"`)
**When** je s√©lectionne le n≈ìud et clique sur "‚ú® G√©n√©rer pour tous les choix"
**Then** un n≈ìud est g√©n√©r√© pour chaque choix non connect√©
**And** tous les n≈ìuds sont g√©n√©r√©s en <2 minutes (NFR-P2 batch, g√©n√©ration parall√®le)
**And** chaque n≈ìud est automatiquement li√© au n≈ìud parent (connexion parent‚Üíenfant via `via_choice_index`, voir Story 1.9)

**Given** je lance une g√©n√©ration batch
**When** la g√©n√©ration est en cours
**Then** la modal de progression affiche "G√©n√©ration batch : X/Y n≈ìuds" avec progression en temps r√©el
**And** je peux interrompre la g√©n√©ration batch (tous les n≈ìuds en cours sont annul√©s, voir Epic 0 Story 0.8)

**Given** la g√©n√©ration batch r√©ussit partiellement (ex: 5/8 n≈ìuds g√©n√©r√©s, 3 √©checs)
**When** les r√©sultats sont affich√©s
**Then** les 5 n≈ìuds r√©ussis sont ajout√©s au graphe avec auto-link
**And** un message d'erreur liste les 3 choix qui ont √©chou√© avec raison (ex: "Choix 'Questionner' : timeout LLM")
**And** je peux r√©g√©n√©rer individuellement les choix √©chou√©s (voir Story 1.10)

**Given** je g√©n√®re un batch avec contexte GDD
**When** les n≈ìuds sont g√©n√©r√©s
**Then** chaque n≈ìud utilise le m√™me contexte GDD (coh√©rence narrative)
**And** les n≈ìuds sont vari√©s (pas de r√©p√©tition, chaque choix m√®ne √† un dialogue unique)
**And** chaque n≈ìud est g√©n√©r√© avec le contexte du choix sp√©cifique (texte du choix inclus dans le prompt)

**Given** certains choix du n≈ìud parent ont d√©j√† un `targetNode` connect√©
**When** je lance une g√©n√©ration batch
**Then** seuls les choix non connect√©s sont g√©n√©r√©s (pas de r√©g√©n√©ration des choix d√©j√† connect√©s)
**And** un message informatif s'affiche "X choix d√©j√† connect√©(s), Y nouveau(x) n≈ìud(s) g√©n√©r√©(s)"

**Technical Requirements:**
- Backend : Endpoint `/api/v1/unity-dialogues/graph/generate-node` (existant) avec param√®tre `generate_all_choices: bool`
  - Utilise `GraphGenerationService.generate_nodes_for_all_choices()` avec g√©n√©ration parall√®le (asyncio.gather)
  - Filtre automatiquement les choix d√©j√† connect√©s (targetNode existe et ‚â† "END")
- Service : `GraphGenerationService` avec gestion erreurs par choix (√©chec d'un choix n'arr√™te pas les autres)
- Frontend : 
  - Composant `AIGenerationPanel.tsx` (existant) avec bouton "‚ú® G√©n√©rer pour tous les choix"
  - Progression batch : `batchProgress` state avec `{current, total}` mis √† jour en temps r√©el
- Progress : Modal `GenerationProgressModal` affiche progression batch (X/Y n≈ìuds g√©n√©r√©s)
- Auto-link : Chaque n≈ìud g√©n√©r√© est connect√© au parent via `suggested_connections` avec `via_choice_index` (voir Story 1.9)
- Interruption : Support interruption batch (Epic 0 Story 0.8) - annule toutes les g√©n√©rations en cours
- Tests : Unit (batch g√©n√©ration parall√®le), Integration (API batch avec √©checs partiels), E2E (workflow batch complet)

**Dev Notes:**
- **G√©n√©ration parall√®le :** Les n≈ìuds sont g√©n√©r√©s en parall√®le avec `asyncio.gather()` pour optimiser le temps de g√©n√©ration. Si un choix √©choue, les autres continuent.
- **Filtrage automatique :** Seuls les choix sans `targetNode` (ou avec `targetNode === "END"`) sont g√©n√©r√©s. Les choix d√©j√† connect√©s sont ignor√©s.
- **Limite de choix :** Pas de limite artificielle (3-8). Tous les choix non connect√©s sont g√©n√©r√©s. Si un n≈ìud a 10 choix non connect√©s, 10 n≈ìuds seront g√©n√©r√©s.
- **S√©lection manuelle :** La s√©lection manuelle de 3-8 choix sp√©cifiques n'est pas dans le scope. Si besoin, cr√©er une story s√©par√©e "Story 1.2b: G√©n√©rer batch avec s√©lection manuelle de choix".

**References:** FR2 (g√©n√©ration batch), NFR-P2 (LLM Generation <2min batch), Story 1.9 (auto-link), Story 1.10 (r√©g√©n√©ration), Epic 0 Story 0.8 (interruption)

---

### Story 1.3: Sp√©cifier instructions de g√©n√©ration (tone, style, theme) (FR3)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â** (am√©liorations mineures possibles)

**Note:** Cette fonctionnalit√© existe d√©j√†. Les champs `userInstructions` sont disponibles dans `AIGenerationPanel.tsx` et `GenerationPanel.tsx`, et sont int√©gr√©s dans le prompt LLM.

**Am√©liorations mineures possibles :**
- Warning si instructions >500 mots
- Message "Instructions par d√©faut utilis√©es" si vide

As a **utilisateur g√©n√©rant des dialogues**,
I want **sp√©cifier des instructions de g√©n√©ration (tone, style, theme) pour chaque g√©n√©ration**,
So that **les dialogues g√©n√©r√©s correspondent exactement √† l'ambiance et au style narratif souhait√©s**.

**Acceptance Criteria:**

**Given** je suis sur l'√©cran de g√©n√©ration
**When** je saisis des instructions dans le champ "Instructions" (ex: "Tone: sombre, Style: po√©tique, Theme: trahison")
**Then** les instructions sont incluses dans le prompt LLM
**And** le n≈ìud g√©n√©r√© refl√®te ces instructions (tone sombre, style po√©tique, theme trahison)

**Given** j'ai sauvegard√© un preset (Epic 0 Story 0.4)
**When** je charge le preset
**Then** les instructions du preset sont pr√©-remplies dans le champ "Instructions"
**And** je peux modifier les instructions avant g√©n√©ration

**Given** je sp√©cifie des instructions vides
**When** je lance une g√©n√©ration
**Then** des instructions par d√©faut sont utilis√©es (tone neutre, style standard)
**And** un message informatif s'affiche "Instructions par d√©faut utilis√©es"

**Given** je sp√©cifie des instructions tr√®s longues (>500 mots)
**When** je lance une g√©n√©ration
**Then** un warning s'affiche "Instructions longues - peut affecter le budget tokens"
**And** la g√©n√©ration continue normalement (pas de blocage)

**Technical Requirements:**
- Frontend : Champ texte `userInstructions` dans `GenerationPanel.tsx` (existant, √† am√©liorer)
- Backend : Int√©gration instructions dans `PromptEngine.build_prompt()` (existant)
- Validation : Longueur max instructions (optionnel, warning si >500 mots)
- Presets : Integration avec Epic 0 Story 0.4 (presets incluent instructions)
- Tests : Unit (instructions incluses dans prompt), Integration (g√©n√©ration avec instructions), E2E (instructions appliqu√©es)

**References:** FR3 (instructions g√©n√©ration), Epic 0 Story 0.4 (presets), FR55-63 (templates)

---

### Story 1.4: Accepter ou rejeter n≈ìuds g√©n√©r√©s inline (FR4)

**Status:** üî¥ **PRIORIT√â A - √Ä IMPL√âMENTER**

**Valeur :** Permet l'it√©ration rapide sur la qualit√© des dialogues sans workflow complexe. Bloque l'US 1.10 (r√©g√©n√©ration).

As a **utilisateur g√©n√©rant des dialogues**,
I want **accepter ou rejeter les n≈ìuds g√©n√©r√©s directement dans le graphe**,
So that **je peux it√©rer rapidement sur la qualit√© des dialogues sans workflow complexe**.

**Acceptance Criteria:**

**Given** un n≈ìud vient d'√™tre g√©n√©r√© et appara√Æt dans le graphe
**When** je survole le n≈ìud
**Then** des boutons "Accepter" (‚úì) et "Rejeter" (‚úó) s'affichent sur le n≈ìud
**And** le n≈ìud est en √©tat "pending" (couleur orange/border dashed)

**Given** je clique sur "Accepter"
**When** le n≈ìud est accept√©
**Then** le n≈ìud passe en √©tat "accepted" (couleur verte/border solid)
**And** le n≈ìud est sauvegard√© dans le dialogue (persist√©)
**And** les boutons Accepter/Rejeter disparaissent

**Given** je clique sur "Rejeter"
**When** le n≈ìud est rejet√©
**Then** le n≈ìud est supprim√© du graphe (pas sauvegard√©)
**And** un message "N≈ìud rejet√©" s'affiche
**And** je peux r√©g√©n√©rer le n≈ìud avec instructions ajust√©es (voir Story 1.10)

**Given** j'ai plusieurs n≈ìuds pending dans le graphe
**When** je navigue dans le graphe
**Then** tous les n≈ìuds pending affichent les boutons Accepter/Rejeter
**And** je peux accepter/rejeter chaque n≈ìud ind√©pendamment

**Given** je ferme l'application avec des n≈ìuds pending
**When** je rouvre l'application
**Then** les n≈ìuds pending sont restaur√©s (session recovery)
**And** je peux toujours accepter/rejeter ces n≈ìuds

**Technical Requirements:**
- Frontend : Composant `DialogueNode.tsx` avec √©tat "pending/accepted/rejected" + boutons inline
- Zustand store : `useGraphStore` avec m√©thode `acceptNode(nodeId)`, `rejectNode(nodeId)`
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}/accept` (POST), `/reject` (POST)
- State : N≈ìuds pending stock√©s dans dialogue JSON avec flag `status: "pending"`
- Tests : Unit (accept/reject logic), Integration (API accept/reject), E2E (workflow accept/reject)

**References:** FR4 (accepter/rejeter), FR95-101 (session management), Story 1.10 (r√©g√©n√©ration)

---

### Story 1.5: √âditer manuellement le contenu des n≈ìuds g√©n√©r√©s (FR5)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√†. Le composant `NodeEditorPanel.tsx` permet l'√©dition compl√®te des n≈ìuds (texte, speaker, metadata).

As a **utilisateur cr√©ant des dialogues**,
I want **√©diter manuellement le contenu des n≈ìuds g√©n√©r√©s (texte, speaker, metadata)**,
So that **je peux affiner et personnaliser les dialogues g√©n√©r√©s par l'IA**.

**Acceptance Criteria:**

**Given** un n≈ìud est g√©n√©r√© et accept√© dans le graphe
**When** je double-clique sur le n≈ìud (ou clic droit ‚Üí "√âditer")
**Then** un panneau d'√©dition s'ouvre avec les champs : texte, speaker, metadata
**And** je peux modifier chaque champ

**Given** je modifie le texte d'un n≈ìud
**When** je sauvegarde (Ctrl+S ou bouton "Sauvegarder")
**Then** les modifications sont persist√©es dans le dialogue
**And** un indicateur "Modifi√©" s'affiche sur le n≈ìud (ic√¥ne √©toile)
**And** l'auto-save (Epic 0 Story 0.5) sauvegarde les modifications dans les 2 minutes

**Given** je modifie le speaker d'un n≈ìud
**When** le speaker n'existe pas dans le GDD
**Then** un warning s'affiche "Speaker 'X' non trouv√© dans GDD"
**And** je peux quand m√™me sauvegarder (speaker custom autoris√©)

**Given** je modifie les metadata d'un n≈ìud (tags, conditions, effets)
**When** je sauvegarde
**Then** les metadata sont valid√©es (format JSON Unity)
**And** les erreurs de validation sont affich√©es avant sauvegarde

**Given** j'annule l'√©dition (Escape ou bouton "Annuler")
**When** je ferme le panneau d'√©dition
**Then** les modifications non sauvegard√©es sont perdues
**And** un message de confirmation s'affiche si modifications non sauvegard√©es

**Technical Requirements:**
- Frontend : Composant `NodeEditorPanel.tsx` avec formulaires texte/speaker/metadata
- Zustand store : `useGraphStore` avec m√©thode `updateNode(nodeId, updates)`
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}` (PUT) pour mise √† jour n≈ìud
- Validation : Format Unity JSON (Pydantic models) avant sauvegarde
- Integration : Epic 0 Story 0.5 (auto-save) pour sauvegarde automatique
- Tests : Unit (√©dition n≈ìud), Integration (API update), E2E (workflow √©dition complet)

**References:** FR5 (√©dition manuelle), FR48 (validation JSON Unity), Epic 0 Story 0.5 (auto-save)

---

### Story 1.6: Cr√©er manuellement des n≈ìuds sans LLM (FR6)

**Status:** üî¥ **PRIORIT√â A - √Ä IMPL√âMENTER**

**Valeur :** Compl√®te le workflow de cr√©ation en permettant d'ajouter des dialogues sp√©cifiques sans utiliser l'IA.

**Note:** La m√©thode `addNode()` existe dans le store, mais il manque un bouton "Nouveau n≈ìud" visible dans l'UI.

As a **utilisateur cr√©ant des dialogues**,
I want **cr√©er des n≈ìuds de dialogue manuellement sans g√©n√©ration LLM**,
So that **je peux ajouter des dialogues sp√©cifiques ou corriger des n≈ìuds sans utiliser l'IA**.

**Acceptance Criteria:**

**Given** je suis dans l'√©diteur de graphe
**When** je clique sur "Nouveau n≈ìud" (bouton + ou menu contextuel)
**Then** un n≈ìud vide est cr√©√© dans le graphe avec stableID unique
**And** le panneau d'√©dition s'ouvre automatiquement pour remplir le contenu

**Given** je cr√©e un n≈ìud manuellement
**When** je remplis les champs (texte, speaker, metadata)
**Then** le n≈ìud est sauvegard√© avec le m√™me format que les n≈ìuds g√©n√©r√©s
**And** le n≈ìud est imm√©diatement visible dans le graphe

**Given** je cr√©e un n≈ìud manuellement sans texte
**When** je sauvegarde
**Then** un warning s'affiche "N≈ìud vide - ajouter du texte"
**And** je peux quand m√™me sauvegarder (n≈ìud placeholder autoris√©)

**Given** je cr√©e un n≈ìud manuellement
**When** je cr√©e le n≈ìud
**Then** je peux imm√©diatement cr√©er des connexions vers d'autres n≈ìuds (drag-and-drop)
**And** le n≈ìud peut recevoir des connexions depuis d'autres n≈ìuds

**Given** je cr√©e plusieurs n≈ìuds manuellement rapidement
**When** les n≈ìuds sont cr√©√©s
**Then** chaque n≈ìud a un stableID unique (pas de collision)
**And** les n≈ìuds sont positionn√©s automatiquement dans le graphe (auto-layout)

**Technical Requirements:**
- Frontend : Bouton "Nouveau n≈ìud" dans `GraphEditor.tsx` + menu contextuel
- Zustand store : `useGraphStore` avec m√©thode `createEmptyNode()` retournant n≈ìud avec stableID
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes` (POST) pour cr√©er n≈ìud vide
- Auto-layout : Positionnement automatique nouveau n≈ìud (React Flow auto-layout)
- Integration : M√™me format Unity JSON que n≈ìuds g√©n√©r√©s (coh√©rence)
- Tests : Unit (cr√©ation n≈ìud vide), Integration (API create node), E2E (workflow cr√©ation manuelle)

**References:** FR6 (cr√©ation manuelle), FR22-35 (graph editor), Epic 0 Story 0.1 (stableID)

---

### Story 1.7: Dupliquer des n≈ìuds existants pour cr√©er des variantes (FR7)

**Status:** üü° **PRIORIT√â B - √Ä IMPL√âMENTER**

**Valeur :** Gain de productivit√© en permettant de cr√©er rapidement des variantes sans recr√©er depuis z√©ro.

As a **utilisateur cr√©ant des dialogues**,
I want **dupliquer des n≈ìuds existants pour cr√©er des variantes rapidement**,
So that **je peux it√©rer sur des versions alternatives sans recr√©er le n≈ìud depuis z√©ro**.

**Acceptance Criteria:**

**Given** j'ai un n≈ìud dans le graphe
**When** je s√©lectionne le n≈ìud et clique sur "Dupliquer" (menu contextuel ou bouton)
**Then** une copie du n≈ìud est cr√©√©e avec un nouveau stableID unique
**And** le n≈ìud dupliqu√© est positionn√© √† c√¥t√© du n≈ìud original (offset visuel)
**And** le panneau d'√©dition s'ouvre pour modifier la copie

**Given** je duplique un n≈ìud avec des connexions
**When** le n≈ìud est dupliqu√©
**Then** le n≈ìud dupliqu√© n'a PAS de connexions (copie isol√©e)
**And** je peux cr√©er de nouvelles connexions pour la variante

**Given** je duplique un n≈ìud avec metadata (tags, conditions, effets)
**When** le n≈ìud est dupliqu√©
**Then** toutes les metadata sont copi√©es dans le n≈ìud dupliqu√©
**And** je peux modifier les metadata ind√©pendamment

**Given** je duplique plusieurs n≈ìuds en s√©lection multiple
**When** je s√©lectionne 3 n≈ìuds et clique "Dupliquer"
**Then** 3 copies sont cr√©√©es (une par n≈ìud s√©lectionn√©)
**And** chaque copie a un stableID unique
**And** les copies sont positionn√©es en groupe √† c√¥t√© des originaux

**Given** je duplique un n≈ìud
**When** je modifie le n≈ìud dupliqu√©
**Then** les modifications n'affectent pas le n≈ìud original
**And** les deux n≈ìuds sont ind√©pendants (pas de lien de d√©pendance)

**Technical Requirements:**
- Frontend : Action "Dupliquer" dans menu contextuel `DialogueNode.tsx` + s√©lection multiple
- Zustand store : `useGraphStore` avec m√©thode `duplicateNode(nodeId)` retournant nouveau n≈ìud
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}/duplicate` (POST) pour duplication
- Positionnement : Offset visuel (ex: +50px x, +50px y) pour distinguer copie de l'original
- Metadata : Copie profonde (deep copy) de toutes les propri√©t√©s sauf stableID et connexions
- Tests : Unit (duplication logique), Integration (API duplicate), E2E (workflow duplication)

**References:** FR7 (duplication), FR31-32 (s√©lection multiple), Epic 0 Story 0.1 (stableID)

---

### Story 1.8: Supprimer des n≈ìuds du dialogue (FR8)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√†. La m√©thode `deleteNode()` existe avec modal de confirmation.

As a **utilisateur cr√©ant des dialogues**,
I want **supprimer des n≈ìuds du dialogue**,
So that **je peux nettoyer et r√©organiser le graphe en supprimant les n≈ìuds non d√©sir√©s**.

**Acceptance Criteria:**

**Given** j'ai un n≈ìud dans le graphe
**When** je s√©lectionne le n≈ìud et clique sur "Supprimer" (menu contextuel ou touche Delete)
**Then** une confirmation s'affiche "Supprimer ce n≈ìud ? Les connexions seront √©galement supprim√©es"
**And** j'ai les options "Supprimer" et "Annuler"

**Given** je confirme la suppression
**When** le n≈ìud est supprim√©
**Then** le n≈ìud dispara√Æt du graphe
**And** toutes les connexions (entrantes et sortantes) sont √©galement supprim√©es
**And** le n≈ìud est supprim√© du dialogue (persist√©)

**Given** je supprime un n≈ìud avec plusieurs connexions
**When** le n≈ìud est supprim√©
**Then** un warning s'affiche "N≈ìud supprim√© - X connexions supprim√©es"
**And** les n≈ìuds orphelins sont d√©tect√©s (validation structurelle, voir Epic 4)

**Given** je supprime plusieurs n≈ìuds en s√©lection multiple
**When** je s√©lectionne 3 n≈ìuds et appuie sur Delete
**Then** une confirmation s'affiche "Supprimer 3 n≈ìuds ?"
**And** tous les n≈ìuds s√©lectionn√©s sont supprim√©s en une seule action

**Given** je supprime un n≈ìud par erreur
**When** je supprime le n≈ìud
**Then** je peux annuler avec Ctrl+Z (undo, voir FR35)
**And** le n≈ìud et ses connexions sont restaur√©s

**Technical Requirements:**
- Frontend : Action "Supprimer" dans menu contextuel `DialogueNode.tsx` + touche Delete keyboard
- Zustand store : `useGraphStore` avec m√©thode `deleteNode(nodeId)` + confirmation modal
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}` (DELETE) pour suppression
- Connexions : Suppression cascade des connexions (orphans d√©tect√©s par validation)
- Undo/Redo : Integration avec syst√®me undo/redo (FR35, Epic 2)
- Tests : Unit (suppression logique), Integration (API delete), E2E (workflow suppression + undo)

**References:** FR8 (suppression), FR35 (undo/redo), FR40 (orphans), Epic 4 (validation structurelle)

---

### Story 1.9: Auto-link des n≈ìuds g√©n√©r√©s au graphe existant (FR9)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√†. Les connexions automatiques sont cr√©√©es via `suggested_connections` dans l'API de g√©n√©ration.

As a **utilisateur g√©n√©rant des dialogues**,
I want **que les n≈ìuds g√©n√©r√©s soient automatiquement li√©s √† la structure du graphe existante**,
So that **je n'ai pas √† cr√©er manuellement les connexions apr√®s chaque g√©n√©ration**.

**Acceptance Criteria:**

**Given** je g√©n√®re un n≈ìud depuis un n≈ìud parent existant
**When** le n≈ìud est g√©n√©r√©
**Then** une connexion automatique est cr√©√©e du n≈ìud parent vers le nouveau n≈ìud
**And** la connexion est visible dans le graphe (fl√®che parent‚Üíenfant)

**Given** je g√©n√®re un batch de n≈ìuds depuis des choix joueur
**When** les n≈ìuds sont g√©n√©r√©s
**Then** chaque n≈ìud est automatiquement li√© au n≈ìud parent (connexion depuis le choix vers le nouveau n≈ìud)
**And** chaque connexion utilise le texte du choix comme label (ex: "Accepter" ‚Üí n≈ìud g√©n√©r√©)

**Given** je g√©n√®re un n≈ìud "Continue" (suite d'un dialogue existant)
**When** le n≈ìud est g√©n√©r√©
**Then** le n≈ìud est automatiquement li√© au n≈ìud cible sp√©cifi√© (targetNode mis √† jour)
**And** la connexion est cr√©√©e dans le bon sens (parent‚Üínouveau n≈ìud)

**Given** je g√©n√®re un n≈ìud sans contexte parent (g√©n√©ration standalone)
**When** le n≈ìud est g√©n√©r√©
**Then** le n≈ìud est cr√©√© sans connexion automatique (n≈ìud isol√©)
**And** je peux cr√©er manuellement des connexions vers ce n≈ìud

**Given** je g√©n√®re un n≈ìud qui cr√©e un cycle (A ‚Üí B ‚Üí C ‚Üí A)
**When** le n≈ìud est g√©n√©r√©
**Then** le cycle est d√©tect√© par la validation (Epic 0 Story 0.6)
**And** un warning s'affiche "Cycle d√©tect√©" (non-bloquant)
**And** la connexion est cr√©√©e quand m√™me (cycles autoris√©s pour dialogues r√©cursifs)

**Technical Requirements:**
- Backend : Service `UnityDialogueGenerationService` avec m√©thode `autoLinkNode(parentNodeId, newNodeId, choiceText?)`
- Frontend : Hook `useAutoLink` dans `GenerationPanel.tsx` qui cr√©e connexion apr√®s g√©n√©ration
- Zustand store : `useGraphStore` avec m√©thode `createConnection(fromNodeId, toNodeId, label?)`
- Connexions : Format React Flow edge avec `source`, `target`, `label` (texte choix)
- Validation : Integration avec Epic 0 Story 0.6 (d√©tection cycles)
- Tests : Unit (auto-link logique), Integration (connexion cr√©√©e), E2E (workflow auto-link complet)

**References:** FR9 (auto-link), Story 1.1 (g√©n√©ration single), Story 1.2 (g√©n√©ration batch), Epic 0 Story 0.6 (validation cycles)

---

### Story 1.10: R√©g√©n√©rer des n≈ìuds rejet√©s avec instructions ajust√©es (FR10)

**Status:** üî¥ **PRIORIT√â A - √Ä IMPL√âMENTER**

**Valeur :** Permet l'it√©ration sur la qualit√© sans perdre le contexte. D√©pend de l'US 1.4 (accept/reject).

**Note:** N√©cessite l'impl√©mentation de l'US 1.4 en premier.

As a **utilisateur g√©n√©rant des dialogues**,
I want **r√©g√©n√©rer des n≈ìuds rejet√©s avec des instructions ajust√©es**,
So that **je peux it√©rer sur la qualit√© des dialogues sans perdre le contexte de la g√©n√©ration pr√©c√©dente**.

**Acceptance Criteria:**

**Given** j'ai rejet√© un n≈ìud g√©n√©r√© (voir Story 1.4)
**When** je s√©lectionne le n≈ìud rejet√© et clique sur "R√©g√©n√©rer"
**Then** un panneau s'ouvre avec les instructions originales pr√©-remplies
**And** je peux modifier les instructions avant r√©g√©n√©ration

**Given** je modifie les instructions (ex: "Tone plus sombre, moins de r√©p√©tition")
**When** je lance la r√©g√©n√©ration
**Then** un nouveau n≈ìud est g√©n√©r√© avec les instructions ajust√©es
**And** le n≈ìud rejet√© est remplac√© par le nouveau n≈ìud (m√™me position dans graphe)
**And** les connexions du n≈ìud rejet√© sont pr√©serv√©es (m√™me parent/enfant)

**Given** je r√©g√©n√®re un n≈ìud plusieurs fois
**When** je r√©g√©n√®re 3 fois le m√™me n≈ìud
**Then** l'historique des instructions est sauvegard√© (3 versions)
**And** je peux voir les instructions pr√©c√©dentes dans un dropdown "Historique"

**Given** je r√©g√©n√®re un n≈ìud batch (partie d'un batch de 5 n≈ìuds)
**When** je r√©g√©n√®re un seul n≈ìud du batch
**Then** seul ce n≈ìud est r√©g√©n√©r√© (pas tout le batch)
**And** les autres n≈ìuds du batch restent inchang√©s

**Given** je r√©g√©n√®re un n≈ìud avec un contexte GDD modifi√©
**When** le contexte GDD a chang√© depuis la g√©n√©ration originale
**Then** le nouveau contexte GDD est utilis√© pour la r√©g√©n√©ration
**And** un message informatif s'affiche "Contexte GDD mis √† jour depuis la g√©n√©ration originale"

**Technical Requirements:**
- Frontend : Bouton "R√©g√©n√©rer" dans menu contextuel `DialogueNode.tsx` pour n≈ìuds rejet√©s
- Composant : `RegenerateNodeModal.tsx` avec champ instructions pr√©-rempli + historique
- Backend : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}/regenerate` (POST) avec instructions ajust√©es
- Historique : Stockage instructions pr√©c√©dentes dans metadata n≈ìud (`regenerationHistory: [...]`)
- Connexions : Pr√©servation connexions lors remplacement n≈ìud (m√™me stableID ou mapping)
- Tests : Unit (r√©g√©n√©ration logique), Integration (API regenerate), E2E (workflow r√©g√©n√©ration)

**References:** FR10 (r√©g√©n√©ration), Story 1.4 (rejeter n≈ìuds), FR3 (instructions), Story 1.1 (g√©n√©ration)

---

### Story 1.11: Estimer le co√ªt LLM avant g√©n√©ration (FR72)

**Status:** üü° **PRIORIT√â B - √Ä IMPL√âMENTER** (UI manquante)

**Valeur :** Donne le contr√¥le sur le budget avant de lancer une g√©n√©ration co√ªteuse.

**Note:** L'estimation existe dans le middleware, mais il manque une UI d√©di√©e pour afficher l'estimation avant g√©n√©ration.

As a **utilisateur g√©n√©rant des dialogues**,
I want **voir une estimation du co√ªt LLM avant de lancer la g√©n√©ration**,
So that **je peux g√©rer mon budget et d√©cider si je veux proc√©der avec la g√©n√©ration**.

**Acceptance Criteria:**

**Given** j'ai configur√© un contexte GDD et des instructions
**When** je clique sur "Estimer le co√ªt" (bouton avant "G√©n√©rer")
**Then** une estimation s'affiche avec : co√ªt estim√© (‚Ç¨), tokens estim√©s (prompt + completion), provider s√©lectionn√©
**And** l'estimation se calcule en <1 seconde (pas de latence perceptible)

**Given** je modifie le contexte GDD (ajout personnage)
**When** le contexte change
**Then** l'estimation est recalcul√©e automatiquement
**And** le nouveau co√ªt estim√© s'affiche (mise √† jour en temps r√©el)

**Given** je change de provider LLM (OpenAI ‚Üí Mistral)
**When** le provider change
**Then** l'estimation est recalcul√©e avec les prix du nouveau provider
**And** la diff√©rence de co√ªt est affich√©e (ex: "Mistral: -30% vs OpenAI")

**Given** je lance une g√©n√©ration batch (5 n≈ìuds)
**When** j'estime le co√ªt
**Then** l'estimation affiche le co√ªt total (5 √ó co√ªt single n≈ìud)
**And** un breakdown par n≈ìud est disponible (d√©plier pour voir d√©tails)

**Given** l'estimation d√©passe mon budget (90% ou 100%)
**When** j'estime le co√ªt
**Then** un warning s'affiche "Budget atteint √† 90%" ou "Budget d√©pass√© - g√©n√©ration bloqu√©e" (voir Epic 0 Story 0.7)
**And** le bouton "G√©n√©rer" est d√©sactiv√© si budget 100% d√©pass√©

**Technical Requirements:**
- Backend : Endpoint `/api/v1/dialogues/estimate-cost` (POST) avec contexte + instructions, retourne estimation
- Service : `CostEstimationService` calcule tokens (prompt builder) + prix provider (config)
- Frontend : Composant `CostEstimationBadge.tsx` affiche estimation + bouton "Estimer" dans `GenerationPanel.tsx`
- Cache : Estimation mise en cache (hash prompt) pour √©viter recalculs inutiles
- Integration : Epic 0 Story 0.7 (cost governance) pour v√©rification budget
- Tests : Unit (calcul estimation), Integration (API estimation), E2E (workflow estimation)

**References:** FR72 (estimation co√ªt), Epic 0 Story 0.7 (cost governance), FR77 (prompt transparency)

---

### Story 1.12: Afficher breakdown des co√ªts par dialogue (FR73)

**Status:** üü¢ **PRIORIT√â C - NICE-TO-HAVE**

**Valeur :** Analytics avanc√©s pour optimiser les co√ªts. Utile mais pas critique pour le workflow principal.

As a **utilisateur g√©n√©rant des dialogues**,
I want **voir le breakdown d√©taill√© des co√ªts par dialogue (co√ªt total, co√ªt par n≈ìud)**,
So that **je peux analyser o√π mes co√ªts LLM sont concentr√©s et optimiser mes g√©n√©rations**.

**Acceptance Criteria:**

**Given** j'ai g√©n√©r√© plusieurs n≈ìuds dans un dialogue
**When** j'ouvre le panneau "Co√ªts" du dialogue
**Then** je vois : co√ªt total dialogue (‚Ç¨), nombre de n≈ìuds g√©n√©r√©s, co√ªt moyen par n≈ìud
**And** un graphique montre la distribution des co√ªts (bar chart par n≈ìud)

**Given** je consulte le breakdown de co√ªts
**When** je clique sur un n≈ìud dans le graphique
**Then** les d√©tails du n≈ìud s'affichent : tokens prompt, tokens completion, co√ªt exact, timestamp g√©n√©ration
**And** je peux voir le prompt utilis√© pour ce n≈ìud (voir Story 1.14)

**Given** j'ai plusieurs dialogues dans le syst√®me
**When** je compare les co√ªts entre dialogues
**Then** je peux trier les dialogues par co√ªt total (plus cher ‚Üí moins cher)
**And** un indicateur visuel montre les dialogues les plus co√ªteux (rouge = cher, vert = √©conomique)

**Given** je g√©n√®re un nouveau n≈ìud dans un dialogue existant
**When** le n≈ìud est g√©n√©r√©
**Then** le breakdown de co√ªts est mis √† jour automatiquement
**And** le co√ªt total dialogue augmente du co√ªt du nouveau n≈ìud

**Given** je supprime un n≈ìud d'un dialogue
**When** le n≈ìud est supprim√©
**Then** le co√ªt du n≈ìud supprim√© reste dans l'historique (pas supprim√© du breakdown)
**And** un indicateur "N≈ìud supprim√©" s'affiche √† c√¥t√© du co√ªt dans le breakdown

**Technical Requirements:**
- Backend : Endpoint `/api/v1/dialogues/{id}/costs` (GET) retourne breakdown d√©taill√©
- Service : `CostTrackingService` agr√®ge co√ªts par dialogue depuis `cost_logs` (table Epic 0 Story 0.7)
- Frontend : Composant `DialogueCostBreakdown.tsx` avec graphique (Chart.js ou Recharts) + tableau d√©taill√©
- Graphique : Bar chart co√ªt par n≈ìud, tooltip avec d√©tails au survol
- Integration : Epic 0 Story 0.7 (cost governance) pour donn√©es co√ªts
- Tests : Unit (agr√©gation co√ªts), Integration (API costs), E2E (affichage breakdown)

**References:** FR73 (breakdown co√ªts), Epic 0 Story 0.7 (cost governance), Story 1.14 (logs g√©n√©ration)

---

### Story 1.13: Afficher co√ªts LLM cumulatifs (daily, monthly) (FR74)

**Status:** ‚úÖ **D√âJ√Ä IMPL√âMENT√â**

**Note:** Cette fonctionnalit√© existe d√©j√†. Le composant `UsageDashboard.tsx` et l'endpoint `/api/v1/costs/usage` sont impl√©ment√©s.

As a **utilisateur g√©n√©rant des dialogues**,
I want **voir mes co√ªts LLM cumulatifs (quotidien, mensuel)**,
So that **je peux suivre mon budget global et identifier les tendances de consommation**.

**Acceptance Criteria:**

**Given** je consulte le dashboard de co√ªts
**When** j'ouvre la section "Co√ªts cumulatifs"
**Then** je vois : co√ªt aujourd'hui (‚Ç¨), co√ªt ce mois (‚Ç¨), co√ªt total (tous temps)
**And** un graphique lin√©aire montre l'√©volution des co√ªts sur les 30 derniers jours

**Given** je consulte les co√ªts cumulatifs
**When** je change la p√©riode (quotidien ‚Üí mensuel ‚Üí annuel)
**Then** le graphique se met √† jour avec les donn√©es de la p√©riode s√©lectionn√©e
**And** les totaux sont recalcul√©s (ex: "Janvier 2026: 45‚Ç¨")

**Given** je consulte les co√ªts par provider (OpenAI vs Mistral)
**When** j'ouvre le breakdown par provider
**Then** je vois : co√ªt OpenAI (‚Ç¨), co√ªt Mistral (‚Ç¨), pourcentage de chaque provider
**And** un graphique en camembert montre la r√©partition (ex: "OpenAI 70%, Mistral 30%")

**Given** je d√©pense plus que d'habitude un jour
**When** le co√ªt quotidien d√©passe la moyenne (ex: +50%)
**Then** un indicateur visuel s'affiche "D√©pense √©lev√©e aujourd'hui"
**And** un tooltip explique la raison (ex: "5 g√©n√©rations batch aujourd'hui")

**Given** je configure un budget mensuel (Epic 0 Story 0.7)
**When** je consulte les co√ªts cumulatifs
**Then** un indicateur de progression s'affiche "Budget: 45‚Ç¨ / 100‚Ç¨ (45%)"
**And** une barre de progression visuelle montre l'avancement (vert <90%, orange 90-100%, rouge >100%)

**Technical Requirements:**
- Backend : Endpoint `/api/v1/costs/cumulative` (GET) avec param√®tre `period: daily/monthly/yearly`
- Service : `CostTrackingService` agr√®ge co√ªts depuis `cost_logs` par p√©riode (SQL GROUP BY date)
- Frontend : Composant `CumulativeCostsDashboard.tsx` avec graphique lin√©aire (Chart.js) + indicateurs
- Graphique : Ligne temporelle co√ªts quotidiens/mensuels avec tooltip d√©tails
- Integration : Epic 0 Story 0.7 (cost governance) pour budget + donn√©es co√ªts
- Tests : Unit (agr√©gation p√©riodes), Integration (API cumulative), E2E (affichage dashboard)

**References:** FR74 (co√ªts cumulatifs), Epic 0 Story 0.7 (cost governance), FR76 (budgets)

---

### Story 1.14: Afficher prompt transparency (prompt exact envoy√© au LLM) (FR77)

**Status:** üü¢ **PRIORIT√â C - NICE-TO-HAVE**

**Valeur :** Utile pour le debug avanc√©, mais pas critique pour le workflow principal.

As a **utilisateur g√©n√©rant des dialogues**,
I want **voir le prompt exact envoy√© au LLM pour chaque g√©n√©ration**,
So that **je peux comprendre comment le contexte GDD et les instructions sont utilis√©s et d√©boguer les g√©n√©rations**.

**Acceptance Criteria:**

**Given** un n≈ìud a √©t√© g√©n√©r√©
**When** je s√©lectionne le n≈ìud et clique sur "Voir le prompt" (menu contextuel ou panneau d√©tails)
**Then** un modal s'ouvre affichant le prompt complet envoy√© au LLM
**And** le prompt est format√© avec syntaxe highlight (markdown ou code block)
**And** les sections sont clairement d√©limit√©es (System prompt, Context GDD, Instructions, etc.)

**Given** je consulte le prompt d'une g√©n√©ration
**When** le prompt est affich√©
**Then** je peux copier le prompt (bouton "Copier") pour l'utiliser ailleurs
**And** je peux voir les tokens utilis√©s (prompt tokens, completion tokens, total)

**Given** je g√©n√®re un nouveau n≈ìud
**When** la g√©n√©ration se termine
**Then** le prompt est automatiquement sauvegard√© dans les logs (voir Story 1.15)
**And** je peux consulter le prompt imm√©diatement apr√®s g√©n√©ration

**Given** je consulte le prompt d'une g√©n√©ration batch
**When** le prompt est affich√©
**Then** je vois le prompt de base (identique pour tous les n≈ìuds du batch)
**And** je peux voir les variations sp√©cifiques par n≈ìud (ex: "Choix 1: Accepter", "Choix 2: Refuser")

**Given** je modifie le contexte GDD apr√®s une g√©n√©ration
**When** je consulte le prompt d'une g√©n√©ration ancienne
**Then** le prompt affich√© est celui utilis√© √† l'√©poque (pas le contexte actuel)
**And** un message informatif s'affiche "Prompt historique - contexte GDD depuis modifi√©"

**Technical Requirements:**
- Backend : Stockage prompt dans `generation_logs` (table) avec chaque g√©n√©ration (timestamp, prompt, tokens, cost)
- API : Endpoint `/api/v1/dialogues/{id}/nodes/{nodeId}/prompt` (GET) retourne prompt historique
- Frontend : Composant `PromptViewerModal.tsx` avec syntaxe highlight (react-syntax-highlighter) + bouton copier
- Format : Prompt format√© avec sections (System, Context, Instructions) + line numbers
- Integration : Story 1.15 (generation logs) pour stockage prompts
- Tests : Unit (formatage prompt), Integration (API prompt), E2E (affichage prompt)

**References:** FR77 (prompt transparency), Story 1.15 (generation logs), FR78 (logs)

---

### Story 1.15: Afficher logs de g√©n√©ration (prompts, r√©ponses, co√ªts) (FR78)

**Status:** üü° **PRIORIT√â B - √Ä IMPL√âMENTER** (UI manquante)

**Valeur :** Transparence et debug. Le tracking existe d√©j√†, mais il manque une UI de consultation.

**Note:** Le tracking des co√ªts existe d√©j√† (`LLMUsageService`), mais il manque une interface pour consulter les logs.

As a **utilisateur g√©n√©rant des dialogues**,
I want **consulter les logs de g√©n√©ration (prompts, r√©ponses LLM, co√ªts) pour chaque n≈ìud**,
So that **je peux analyser l'historique des g√©n√©rations et comprendre les patterns de co√ªts/qualit√©**.

**Acceptance Criteria:**

**Given** j'ai g√©n√©r√© plusieurs n≈ìuds dans un dialogue
**When** j'ouvre le panneau "Logs de g√©n√©ration"
**Then** je vois une liste chronologique de toutes les g√©n√©rations (plus r√©cent ‚Üí plus ancien)
**And** chaque entr√©e affiche : timestamp, n≈ìud g√©n√©r√©, co√ªt (‚Ç¨), tokens, provider, statut (succ√®s/√©chec)

**Given** je consulte les logs de g√©n√©ration
**When** je clique sur une entr√©e de log
**Then** les d√©tails s'affichent : prompt complet, r√©ponse LLM brute, co√ªt d√©taill√©, dur√©e g√©n√©ration
**And** je peux voir le prompt (voir Story 1.14) et la r√©ponse format√©e

**Given** je filtre les logs par p√©riode (aujourd'hui, cette semaine, ce mois)
**When** je s√©lectionne une p√©riode
**Then** seuls les logs de cette p√©riode sont affich√©s
**And** un r√©sum√© s'affiche "X g√©n√©rations, Y‚Ç¨ total"

**Given** je filtre les logs par provider (OpenAI vs Mistral)
**When** je s√©lectionne un provider
**Then** seuls les logs de ce provider sont affich√©s
**And** un r√©sum√© s'affiche "X g√©n√©rations OpenAI, Y‚Ç¨ total"

**Given** une g√©n√©ration a √©chou√© (erreur LLM API)
**When** je consulte le log de cette g√©n√©ration
**Then** le statut affiche "√âchec" avec message d'erreur d√©taill√©
**And** le co√ªt affich√© est 0‚Ç¨ (pas de co√ªt pour g√©n√©ration √©chou√©e)
**And** je peux voir la tentative de prompt (si disponible)

**Given** j'exporte les logs de g√©n√©ration
**When** je clique sur "Exporter logs" (CSV ou JSON)
**Then** un fichier est t√©l√©charg√© avec tous les logs (format structur√©)
**And** les logs incluent : timestamp, n≈ìud, prompt, r√©ponse, co√ªt, tokens, provider, statut

**Technical Requirements:**
- Backend : Table `generation_logs` (timestamp, dialogue_id, node_id, prompt, response, tokens, cost, provider, status)
- API : Endpoint `/api/v1/dialogues/{id}/generation-logs` (GET) avec filtres p√©riode/provider
- Frontend : Composant `GenerationLogsPanel.tsx` avec liste chronologique + filtres + export
- Format : Logs format√©s avec timestamps lisibles, co√ªts en ‚Ç¨, statuts color√©s (vert=succ√®s, rouge=√©chec)
- Export : Fonction export CSV/JSON c√¥t√© frontend (download blob)
- Tests : Unit (filtrage logs), Integration (API logs), E2E (affichage + export logs)

**References:** FR78 (generation logs), Story 1.14 (prompt transparency), FR72-74 (co√ªts), Epic 0 Story 0.7 (cost governance)

---

### Story 1.16: Fallback vers provider LLM alternatif en cas d'√©chec (FR79)

**Status:** üü¢ **PRIORIT√â C - NICE-TO-HAVE**

**Valeur :** Robustesse syst√®me. Utile mais peut √™tre report√© √† un Epic futur (robustesse infrastructure).

**Note:** Peut √™tre d√©plac√© vers Epic 0 (infrastructure) si plus logique.

As a **utilisateur g√©n√©rant des dialogues**,
I want **que le syst√®me bascule automatiquement vers un provider LLM alternatif si le provider principal √©choue**,
So that **mes g√©n√©rations ne sont pas interrompues par des pannes temporaires d'un provider**.

**Acceptance Criteria:**

**Given** j'ai configur√© OpenAI comme provider principal et Mistral comme fallback
**When** OpenAI API √©choue (erreur 500, timeout, quota d√©pass√©)
**Then** le syst√®me bascule automatiquement vers Mistral
**And** la g√©n√©ration continue sans interruption visible pour l'utilisateur
**And** un message informatif s'affiche "OpenAI indisponible - bascule vers Mistral"

**Given** le fallback vers Mistral est activ√©
**When** la g√©n√©ration r√©ussit avec Mistral
**Then** le n≈ìud est g√©n√©r√© normalement (m√™me format Unity JSON)
**And** le log de g√©n√©ration indique "Provider: Mistral (fallback depuis OpenAI)"
**And** le co√ªt Mistral est track√© s√©par√©ment (voir Story 1.13)

**Given** les deux providers (OpenAI et Mistral) √©chouent
**When** la g√©n√©ration est tent√©e
**Then** la g√©n√©ration √©choue avec message "Tous les providers LLM sont indisponibles"
**And** aucun co√ªt n'est factur√© (pas de tentative factur√©e)
**And** l'utilisateur peut r√©essayer manuellement plus tard

**Given** je configure les providers de fallback dans les param√®tres
**When** je d√©finis l'ordre de fallback (ex: OpenAI ‚Üí Mistral ‚Üí Anthropic)
**Then** l'ordre est sauvegard√© dans mes pr√©f√©rences
**And** le syst√®me respecte cet ordre lors des fallbacks automatiques

**Given** un fallback est d√©clench√©
**When** je consulte les logs de g√©n√©ration
**Then** le log affiche clairement "Fallback: OpenAI ‚Üí Mistral" avec raison (ex: "Timeout OpenAI")
**And** les m√©triques de fallback sont track√©es (nombre de fallbacks par provider)

**Technical Requirements:**
- Backend : Service `LLMFallbackService` avec logique retry + fallback (provider1 ‚Üí provider2 ‚Üí √©chec)
- Factory : `LLMClientFactory` avec m√©thode `createWithFallback(primary, fallback)` retournant client avec retry
- Retry : Backoff exponentiel (3 tentatives) avant fallback vers provider alternatif
- Logs : √âv√©nement "llm_fallback" dans `generation_logs` avec provider source ‚Üí provider destination + raison
- Frontend : Message toast informatif "Fallback vers [provider]" (non-bloquant, 5s timeout)
- Configuration : Param√®tres utilisateur pour ordre fallback (localStorage + backend preferences)
- Tests : Unit (logique fallback), Integration (API fallback), E2E (workflow fallback complet)

**References:** FR79 (fallback provider), Epic 0 Story 0.3 (Multi-Provider LLM), NFR-R4 (Error Recovery LLM >95%), NFR-I2 (LLM API Reliability >99%)

---

